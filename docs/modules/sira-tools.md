# Sira Tools - Agentåä½œæ‰©å±• (Agent Collaboration Extension)

## æ¦‚è¿°

Sira Tools æ˜¯æ™ºèƒ½ç½‘å…³çš„**Agentåä½œæ‰©å±•æ¨¡å—**ï¼Œä¸“æ³¨äºå®ç°"Assemble Your Crew"è®ºæ–‡çš„æ€æƒ³â€”â€”åŠ¨æ€è®¾è®¡æœ€ä¼˜çš„å¤šAgenté€šä¿¡æ‹“æ‰‘ã€‚å®ƒä¸ºç½‘å…³çš„è‡ªç»„ç»‡æ¨ç†å±‚æä¾›å·¥å…·æ‰§è¡Œå’Œåä½œç¼–æ’èƒ½åŠ›ï¼Œä½¿Agentèƒ½å¤Ÿè‡ªä¸»ç»„åˆå’Œåä½œå®Œæˆå¤æ‚ä»»åŠ¡ã€‚

**åœ¨æ™ºèƒ½ç½‘å…³ç”Ÿæ€ä¸­çš„å®šä½**ï¼šä½œä¸ºæ‰©å±•æ¨¡å—ä¸ºAgentåä½œæä¾›ä¸°å¯Œçš„å·¥å…·ç”Ÿæ€ï¼Œå½“ç½‘å…³éœ€è¦æ‰§è¡Œå…·ä½“ä»»åŠ¡æˆ–ä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’æ—¶ï¼Œä¼šè°ƒç”¨Toolsæ¨¡å—è¿›è¡Œå¢å¼ºå¤„ç†ã€‚

**AOSå“²å­¦ä½“ç°**ï¼š
- **è‡ªç»„ç»‡åä½œ**ï¼šAgentèƒ½åŠ¨æ€å‘ç°å’Œç»„å»ºæœ€ä¼˜åä½œç½‘ç»œ
- **å·¥å…·è‡ªä¸»åˆ›é€ **ï¼šAgentèƒ½ä¸ºè‡ªå·±åˆ›é€ å’Œä¼˜åŒ–å·¥å…·
- **åä½œæ•ˆç‡é©å‘½**ï¼šä»å›ºå®šæµç¨‹èµ°å‘æ™ºèƒ½ç¼–æ’

## AOSæŠ€æœ¯æ ˆæ˜ å°„

### ğŸ¯ å¯¹åº”æŠ€æœ¯é¢†åŸŸ
**AIç¤¾ä¼šçš„"ç‰©ç†æ³•åˆ™" + AIä¸ªä½“çš„"å¤§è„‘"â€”â€”é€šä¿¡ä¸åä½œ**

### ğŸ”§ æ ¸å¿ƒæŠ€æœ¯æ ˆ

#### è‡ªç»„ç»‡çš„æœåŠ¡å‘ç°ä¸è·¯ç”± (Self-Organizing Service Discovery)
- **å‘é‡åŒ–å·¥å…·æè¿°**: å°†å·¥å…·èƒ½åŠ›è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºå­˜å‚¨åœ¨å‘é‡æ•°æ®åº“
- **åŠ¨æ€åä½œæ‹“æ‰‘ç”Ÿæˆ**: "Assemble Your Crew"è®ºæ–‡çš„å®ç°ï¼ŒåŸºäºä»»åŠ¡éœ€æ±‚ç”Ÿæˆæœ€ä¼˜Agentç»„åˆ
- **è¯­ä¹‰åŒ¹é…ç®—æ³•**: ANNæœç´¢æ‰¾åˆ°èƒ½åŠ›æœ€åŒ¹é…çš„å·¥å…·å’ŒAgent

#### è‡ªä¸»å­¦ä¹ ä¸è¿›åŒ– (Autonomous Learning & Evolution)
- **å·¥å…·è‡ªåŠ¨åˆ›é€ **: ToolCreator Agentè‡ªåŠ¨ç¼–å†™ã€æµ‹è¯•å’Œæ³¨å†Œæ–°å·¥å…·
- **ç»éªŒåˆæˆå­¦ä¹ **: é€šè¿‡åˆæˆç»éªŒåŠ é€Ÿå·¥å…·å­¦ä¹ è¿‡ç¨‹
- **é€’å½’è‡ªæˆ‘æ”¹è¿›**: STOP (Self-Taught Optimizer) é€’å½’æ”¹è¿›ä»£ç ç”Ÿæˆ

#### å¤šAgentåä½œæ¡†æ¶ (Multi-Agent Collaboration Framework)
- **åä½œæ‹“æ‰‘è®¾è®¡**: è‡ªåŠ¨è®¾è®¡Agenté—´çš„é€šä¿¡ç½‘ç»œç»“æ„
- **åŠ¨æ€è§’è‰²åˆ†é…**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´Agentè§’è‰²å’Œè´£ä»»
- **åä½œæ•ˆç‡ä¼˜åŒ–**: å­¦ä¹ å†å²åä½œæ¨¡å¼ä»¥ä¼˜åŒ–æœªæ¥ç»„åˆ

#### ç›¸å…³ç ”ç©¶è®ºæ–‡
- **"Assemble Your Crew: Automatic Multi-agent Communication Topology Design"**
- **"Scaling Agent Learning via Experience Synthesis"** (Meta, UC Berkeley)
- **"Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation"** (Google)
- **"Semantic Routing for Multi-Agent Communication"** (2024, ICML)

## æ ¸å¿ƒç»„ä»¶

### ğŸ”§ å·¥å…·æ‰§è¡Œå™¨ (Tool Executor)

#### å·¥å…·æ¥å£è®¾è®¡
```rust
#[async_trait]
pub trait Tool: Send + Sync {
    /// è·å–å·¥å…·å…ƒæ•°æ®
    fn metadata(&self) -> ToolMetadata;

    /// æ‰§è¡Œå·¥å…·
    async fn execute(&self, input: ToolInput) -> Result<ToolOutput, ToolError>;

    /// éªŒè¯è¾“å…¥å‚æ•°
    async fn validate_input(&self, input: &ToolInput) -> Result<(), ToolError>;

    /// è·å–å·¥å…·ä½¿ç”¨è¯´æ˜
    fn usage(&self) -> ToolUsage;

    /// æ£€æŸ¥å·¥å…·å¥åº·çŠ¶æ€
    async fn health_check(&self) -> Result<ToolHealth, ToolError>;
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolMetadata {
    pub id: String,
    pub name: String,
    pub version: String,
    pub category: ToolCategory,
    pub description: String,
    pub author: String,
    pub tags: Vec<String>,
    pub permissions: Vec<String>,
    pub dependencies: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ToolCategory {
    WebInteraction,
    DataProcessing,
    FileSystem,
    Network,
    Database,
    AI,
    System,
    Custom(String),
}
```

#### å·¥å…·æ‰§è¡Œå¼•æ“
```rust
#[derive(Debug)]
pub struct ToolExecutor {
    tool_registry: Arc<RwLock<HashMap<String, Arc<dyn Tool>>>>,
    execution_context: Arc<ExecutionContext>,
    metrics_collector: Arc<MetricsCollector>,
    security_manager: Arc<SecurityManager>,
}

impl ToolExecutor {
    pub async fn execute_tool(&self, execution: ToolExecution) -> Result<ToolResult, ToolError> {
        // æƒé™æ£€æŸ¥
        self.security_manager.check_permissions(&execution).await?;

        // è·å–å·¥å…·
        let tool = self.get_tool(&execution.tool_id).await?;

        // éªŒè¯è¾“å…¥
        tool.validate_input(&execution.input).await?;

        // åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        let context = ExecutionContext {
            execution_id: execution.id.clone(),
            user_id: execution.user_id.clone(),
            session_id: execution.session_id.clone(),
            timeout: execution.timeout,
            ..Default::default()
        };

        // æ‰§è¡Œå·¥å…·
        let start_time = Instant::now();
        let result = match timeout(execution.timeout, tool.execute(execution.input)).await {
            Ok(result) => result,
            Err(_) => return Err(ToolError::Timeout),
        };
        let execution_time = start_time.elapsed();

        // è®°å½•æŒ‡æ ‡
        self.metrics_collector.record_execution(&execution, execution_time).await?;

        // å¤„ç†ç»“æœ
        let tool_result = ToolResult {
            execution_id: execution.id,
            status: ToolExecutionStatus::Completed,
            output: result?,
            execution_time,
            metrics: self.collect_execution_metrics().await?,
        };

        Ok(tool_result)
    }
}
```

### ğŸ¼ å·¥ä½œæµç¼–æ’å™¨ (Workflow Orchestrator)

#### å·¥ä½œæµå®šä¹‰
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Workflow {
    pub id: String,
    pub name: String,
    pub description: String,
    pub version: String,
    pub author: String,
    pub nodes: Vec<WorkflowNode>,
    pub edges: Vec<WorkflowEdge>,
    pub triggers: Vec<WorkflowTrigger>,
    pub variables: HashMap<String, WorkflowVariable>,
    pub metadata: WorkflowMetadata,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowNode {
    pub id: String,
    pub node_type: NodeType,
    pub position: Position,
    pub data: NodeData,
    pub config: NodeConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum NodeType {
    Tool,
    Decision,
    Loop,
    Parallel,
    Merge,
    Delay,
    SubWorkflow,
    Custom(String),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowEdge {
    pub id: String,
    pub source: String,
    pub target: String,
    pub condition: Option<EdgeCondition>,
    pub data_mapping: Option<DataMapping>,
}
```

#### å·¥ä½œæµæ‰§è¡Œå¼•æ“
```rust
#[derive(Debug)]
pub struct WorkflowEngine {
    workflow_store: Arc<WorkflowStore>,
    tool_executor: Arc<ToolExecutor>,
    execution_tracker: Arc<ExecutionTracker>,
    event_bus: Arc<EventBus>,
}

impl WorkflowEngine {
    pub async fn execute_workflow(&self, execution: WorkflowExecution) -> Result<WorkflowResult, WorkflowError> {
        // åŠ è½½å·¥ä½œæµ
        let workflow = self.workflow_store.load_workflow(&execution.workflow_id).await?;

        // åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        let context = WorkflowContext {
            execution_id: execution.id.clone(),
            workflow_id: execution.workflow_id.clone(),
            user_id: execution.user_id.clone(),
            variables: execution.variables.clone(),
            ..Default::default()
        };

        // åˆå§‹åŒ–æ‰§è¡ŒçŠ¶æ€
        let mut state = WorkflowState {
            current_node: workflow.triggers.first().map(|t| t.target_node.clone()),
            completed_nodes: HashSet::new(),
            pending_nodes: workflow.nodes.iter().map(|n| n.id.clone()).collect(),
            node_results: HashMap::new(),
            variables: context.variables.clone(),
        };

        // æ‰§è¡Œå·¥ä½œæµ
        loop {
            match self.execute_next_node(&workflow, &mut state, &context).await? {
                ExecutionResult::Continue => continue,
                ExecutionResult::Completed(result) => {
                    return Ok(WorkflowResult {
                        execution_id: execution.id,
                        status: WorkflowStatus::Completed,
                        result,
                        execution_time: context.start_time.elapsed(),
                        node_results: state.node_results,
                    });
                }
                ExecutionResult::Failed(error) => {
                    return Ok(WorkflowResult {
                        execution_id: execution.id,
                        status: WorkflowStatus::Failed,
                        error: Some(error),
                        execution_time: context.start_time.elapsed(),
                        node_results: state.node_results,
                    });
                }
                ExecutionResult::Suspended => {
                    // ä¿å­˜çŠ¶æ€ä»¥ä¾¿æ¢å¤
                    self.execution_tracker.save_state(&execution.id, &state).await?;
                    break;
                }
            }
        }

        Ok(WorkflowResult {
            execution_id: execution.id,
            status: WorkflowStatus::Suspended,
            execution_time: context.start_time.elapsed(),
            node_results: state.node_results,
        })
    }

    async fn execute_next_node(
        &self,
        workflow: &Workflow,
        state: &mut WorkflowState,
        context: &WorkflowContext,
    ) -> Result<ExecutionResult, WorkflowError> {
        let current_node_id = match &state.current_node {
            Some(id) => id,
            None => return Ok(ExecutionResult::Completed(serde_json::Value::Null)),
        };

        let node = workflow.nodes.iter()
            .find(|n| n.id == *current_node_id)
            .ok_or(WorkflowError::NodeNotFound(current_node_id.clone()))?;

        // æ‰§è¡ŒèŠ‚ç‚¹
        let result = match &node.node_type {
            NodeType::Tool => self.execute_tool_node(node, state, context).await?,
            NodeType::Decision => self.execute_decision_node(node, state, context).await?,
            NodeType::Loop => self.execute_loop_node(node, state, context).await?,
            NodeType::Parallel => self.execute_parallel_node(node, state, context).await?,
            NodeType::Delay => self.execute_delay_node(node, state, context).await?,
            NodeType::SubWorkflow => self.execute_subworkflow_node(node, state, context).await?,
            NodeType::Custom(custom_type) => self.execute_custom_node(custom_type, node, state, context).await?,
        };

        // æ›´æ–°çŠ¶æ€
        state.completed_nodes.insert(current_node_id.clone());
        state.pending_nodes.remove(current_node_id);

        // ç¡®å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        state.current_node = self.determine_next_node(workflow, current_node_id, &result, state).await?;

        Ok(result)
    }
}
```

### ğŸ”€ å†³ç­–èŠ‚ç‚¹ (Decision Nodes)

#### æ¡ä»¶å†³ç­–
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DecisionNode {
    pub conditions: Vec<DecisionCondition>,
    pub default_branch: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DecisionCondition {
    pub expression: String,
    pub target_branch: String,
    pub priority: i32,
}

impl WorkflowEngine {
    async fn execute_decision_node(
        &self,
        node: &WorkflowNode,
        state: &WorkflowState,
        context: &WorkflowContext,
    ) -> Result<ExecutionResult, WorkflowError> {
        let decision_config: DecisionNode = serde_json::from_value(node.config.clone())
            .map_err(|e| WorkflowError::ConfigurationError(e.to_string()))?;

        // è¯„ä¼°æ¡ä»¶
        for condition in &decision_config.conditions {
            if self.evaluate_condition(&condition.expression, state, context).await? {
                return Ok(ExecutionResult::Branch(condition.target_branch.clone()));
            }
        }

        // é»˜è®¤åˆ†æ”¯
        if let Some(default_branch) = &decision_config.default_branch {
            Ok(ExecutionResult::Branch(default_branch.clone()))
        } else {
            Err(WorkflowError::NoValidBranch)
        }
    }

    async fn evaluate_condition(
        &self,
        expression: &str,
        state: &WorkflowState,
        context: &WorkflowContext,
    ) -> Result<bool, WorkflowError> {
        // ä½¿ç”¨è¡¨è¾¾å¼å¼•æ“è¯„ä¼°æ¡ä»¶
        let evaluator = ExpressionEvaluator::new();
        let result = evaluator.evaluate(expression, state, context).await?;
        Ok(result.as_bool().unwrap_or(false))
    }
}
```

#### å¹¶è¡Œæ‰§è¡Œ
```rust
impl WorkflowEngine {
    async fn execute_parallel_node(
        &self,
        node: &WorkflowNode,
        state: &WorkflowState,
        context: &WorkflowContext,
    ) -> Result<ExecutionResult, WorkflowError> {
        let parallel_config: ParallelNode = serde_json::from_value(node.config.clone())
            .map_err(|e| WorkflowError::ConfigurationError(e.to_string()))?;

        // åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        let mut handles = Vec::new();
        for branch in &parallel_config.branches {
            let branch_clone = branch.clone();
            let state_clone = Arc::new(RwLock::new(state.clone()));
            let context_clone = context.clone();
            let engine = self.clone();

            let handle = tokio::spawn(async move {
                engine.execute_branch(&branch_clone, state_clone, &context_clone).await
            });
            handles.push(handle);
        }

        // ç­‰å¾…æ‰€æœ‰åˆ†æ”¯å®Œæˆ
        let results = futures::future::join_all(handles).await;

        // èšåˆç»“æœ
        let mut aggregated_result = serde_json::Value::Array(vec![]);
        for result in results {
            match result {
                Ok(Ok(branch_result)) => {
                    if let serde_json::Value::Array(ref mut arr) = aggregated_result {
                        arr.push(branch_result);
                    }
                }
                Ok(Err(e)) => return Err(e),
                Err(e) => return Err(WorkflowError::TaskPanic(e.to_string())),
            }
        }

        Ok(ExecutionResult::Continue(aggregated_result))
    }
}
```

### ğŸ“Š å·¥å…·æ’ä»¶ç³»ç»Ÿ (Tool Plugin System)

#### æ’ä»¶ç®¡ç†å™¨
```rust
#[derive(Debug)]
pub struct ToolPluginManager {
    plugin_loader: Arc<PluginLoader>,
    tool_registry: Arc<RwLock<HashMap<String, Arc<dyn Tool>>>>,
    plugin_store: Arc<PluginStore>,
}

impl ToolPluginManager {
    pub async fn load_plugin(&self, plugin_path: &Path) -> Result<String, PluginError> {
        // åŠ è½½æ’ä»¶åº“
        let library = self.plugin_loader.load_library(plugin_path).await?;

        // è·å–æ’ä»¶æ„é€ å‡½æ•°
        let constructor: Symbol<extern "C" fn() -> *mut dyn Tool> = unsafe {
            library.get(b"create_tool").map_err(|e| PluginError::SymbolNotFound(e.to_string()))?
        };

        // åˆ›å»ºå·¥å…·å®ä¾‹
        let tool_ptr = constructor();
        let tool = unsafe { Arc::from_raw(tool_ptr) };

        // æ³¨å†Œå·¥å…·
        let tool_id = tool.metadata().id.clone();
        self.tool_registry.write().await.insert(tool_id.clone(), tool);

        // ä¿å­˜æ’ä»¶ä¿¡æ¯
        let plugin_info = PluginInfo {
            id: tool_id.clone(),
            path: plugin_path.to_path_buf(),
            loaded_at: Utc::now(),
            version: "1.0.0".to_string(),
        };
        self.plugin_store.save_plugin_info(&plugin_info).await?;

        Ok(tool_id)
    }

    pub async fn unload_plugin(&self, tool_id: &str) -> Result<(), PluginError> {
        // ä»æ³¨å†Œè¡¨ä¸­ç§»é™¤
        let tool = self.tool_registry.write().await.remove(tool_id)
            .ok_or(PluginError::PluginNotFound(tool_id.to_string()))?;

        // æ‰§è¡Œæ¸…ç†
        if let Some(cleanup) = tool.metadata().cleanup_hook {
            cleanup().await?;
        }

        // å¸è½½æ’ä»¶åº“
        self.plugin_loader.unload_library(tool_id).await?;

        Ok(())
    }
}
```

#### å†…ç½®å·¥å…·ç±»å‹

##### Webäº¤äº’å·¥å…·
```rust
pub struct WebScraperTool {
    client: Arc<reqwest::Client>,
    rate_limiter: Arc<RateLimiter>,
}

#[async_trait]
impl Tool for WebScraperTool {
    fn metadata(&self) -> ToolMetadata {
        ToolMetadata {
            id: "web_scraper".to_string(),
            name: "Web Scraper".to_string(),
            category: ToolCategory::WebInteraction,
            description: "Extract data from web pages".to_string(),
            ..Default::default()
        }
    }

    async fn execute(&self, input: ToolInput) -> Result<ToolOutput, ToolError> {
        let url: String = input.get_parameter("url")?;
        let selector: Option<String> = input.get_parameter_optional("selector")?;

        // é€Ÿç‡é™åˆ¶
        self.rate_limiter.acquire().await?;

        // è·å–ç½‘é¡µ
        let response = self.client.get(&url).send().await?;
        let html = response.text().await?;

        // è§£æå†…å®¹
        let document = scraper::Html::parse_document(&html);
        let content = if let Some(sel) = selector {
            let selector = scraper::Selector::parse(&sel).map_err(|e| ToolError::InvalidParameter(e.to_string()))?;
            document.select(&selector).map(|element| element.text().collect::<String>()).collect::<Vec<_>>().join(" ")
        } else {
            document.root_element().text().collect()
        };

        Ok(ToolOutput::new(serde_json::json!({
            "content": content,
            "url": url,
            "timestamp": Utc::now().timestamp()
        })))
    }
}
```

##### æ–‡ä»¶ç³»ç»Ÿå·¥å…·
```rust
pub struct FileSystemTool {
    allowed_paths: Vec<PathBuf>,
    security_manager: Arc<SecurityManager>,
}

#[async_trait]
impl Tool for FileSystemTool {
    fn metadata(&self) -> ToolMetadata {
        ToolMetadata {
            id: "file_system".to_string(),
            name: "File System Tool".to_string(),
            category: ToolCategory::FileSystem,
            description: "File system operations".to_string(),
            permissions: vec!["file.read".to_string(), "file.write".to_string()],
            ..Default::default()
        }
    }

    async fn execute(&self, input: ToolInput) -> Result<ToolOutput, ToolError> {
        let operation: String = input.get_parameter("operation")?;
        let path: String = input.get_parameter("path")?;

        // å®‰å…¨æ£€æŸ¥
        let path_buf = PathBuf::from(&path);
        self.security_manager.validate_path(&path_buf).await?;

        match operation.as_str() {
            "read" => self.read_file(&path_buf).await,
            "write" => {
                let content: String = input.get_parameter("content")?;
                self.write_file(&path_buf, &content).await
            }
            "list" => self.list_directory(&path_buf).await,
            "delete" => self.delete_file(&path_buf).await,
            _ => Err(ToolError::InvalidParameter(format!("Unknown operation: {}", operation))),
        }
    }
}
```

##### æ•°æ®å¤„ç†å·¥å…·
```rust
pub struct DataProcessorTool {
    processors: HashMap<String, Arc<dyn DataProcessor>>,
}

#[async_trait]
impl Tool for DataProcessorTool {
    fn metadata(&self) -> ToolMetadata {
        ToolMetadata {
            id: "data_processor".to_string(),
            name: "Data Processor".to_string(),
            category: ToolCategory::DataProcessing,
            description: "Process and transform data".to_string(),
            ..Default::default()
        }
    }

    async fn execute(&self, input: ToolInput) -> Result<ToolOutput, ToolError> {
        let processor_type: String = input.get_parameter("processor")?;
        let data: serde_json::Value = input.get_parameter("data")?;

        let processor = self.processors.get(&processor_type)
            .ok_or(ToolError::InvalidParameter(format!("Unknown processor: {}", processor_type)))?;

        let result = processor.process(data).await?;

        Ok(ToolOutput::new(result))
    }
}
```

### ğŸ” å·¥å…·å‘ç°å’Œæ³¨å†Œ (Tool Discovery)

#### è‡ªåŠ¨å‘ç°æœºåˆ¶
```rust
#[derive(Debug)]
pub struct ToolDiscovery {
    plugin_directories: Vec<PathBuf>,
    tool_registry: Arc<ToolRegistry>,
    discovery_scheduler: Arc<DiscoveryScheduler>,
}

impl ToolDiscovery {
    pub async fn discover_tools(&self) -> Result<Vec<ToolInfo>, DiscoveryError> {
        let mut discovered_tools = Vec::new();

        for dir in &self.plugin_directories {
            let tools = self.scan_directory(dir).await?;
            discovered_tools.extend(tools);
        }

        // æ³¨å†Œå‘ç°çš„å·¥å…·
        for tool_info in &discovered_tools {
            self.tool_registry.register_tool_info(tool_info.clone()).await?;
        }

        Ok(discovered_tools)
    }

    async fn scan_directory(&self, dir: &Path) -> Result<Vec<ToolInfo>, DiscoveryError> {
        let mut tools = Vec::new();

        let mut entries = tokio::fs::read_dir(dir).await?;
        while let Some(entry) = entries.next_entry().await? {
            let path = entry.path();

            if self.is_plugin_file(&path) {
                if let Ok(tool_info) = self.extract_tool_info(&path).await {
                    tools.push(tool_info);
                }
            }
        }

        Ok(tools)
    }

    async fn extract_tool_info(&self, path: &Path) -> Result<ToolInfo, DiscoveryError> {
        // åŠ è½½æ’ä»¶è·å–å…ƒæ•°æ®
        let library = Library::new(path)?;
        let metadata_fn: Symbol<extern "C" fn() -> ToolMetadata> = unsafe {
            library.get(b"tool_metadata")?
        };

        let metadata = metadata_fn();

        Ok(ToolInfo {
            id: metadata.id,
            name: metadata.name,
            version: metadata.version,
            path: path.to_path_buf(),
            category: metadata.category,
            discovered_at: Utc::now(),
        })
    }
}
```

## æ¶æ„è®¾è®¡

### å·¥å…·ç”Ÿæ€ç³»ç»Ÿæ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 å·¥å…·ç”Ÿæ€å±‚ (Tool Ecosystem)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  å·¥å…·æ’ä»¶    â”‚ â”‚  å·¥ä½œæµç¼–æ’ â”‚ â”‚  å·¥å…·å‘ç°    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  å·¥å…·æ‰§è¡Œå™¨  â”‚ â”‚  å†³ç­–å¼•æ“  â”‚ â”‚  å¹¶è¡Œæ‰§è¡Œå™¨  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              å¾®å†…æ ¸å·¥å…·æœåŠ¡å±‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å·¥ä½œæµæ‰§è¡Œæµç¨‹
```
1. è§¦å‘å·¥ä½œæµ â†’ 2. åˆå§‹åŒ–ä¸Šä¸‹æ–‡ â†’ 3. æ‰§è¡Œå¼€å§‹èŠ‚ç‚¹
     â†“              â†“              â†“
  äº‹ä»¶ç›‘å¬       å˜é‡å‡†å¤‡       å·¥å…·æ‰§è¡Œ
  å®šæ—¶ä»»åŠ¡       æƒé™æ£€æŸ¥       ç»“æœå¤„ç†
  APIè°ƒç”¨       æ•°æ®éªŒè¯       çŠ¶æ€æ›´æ–°

4. è¯„ä¼°æ¡ä»¶ â†’ 5. æ‰§è¡Œåˆ†æ”¯ â†’ 6. åˆå¹¶ç»“æœ
     â†“              â†“              â†“
  æ¡ä»¶åˆ¤æ–­       é¡ºåºæ‰§è¡Œ       ç»“æœèšåˆ
  æ•°æ®æ˜ å°„       å¹¶è¡Œæ‰§è¡Œ       é”™è¯¯å¤„ç†
  å¾ªç¯æ§åˆ¶       å­æµç¨‹è°ƒç”¨     çŠ¶æ€æŒä¹…åŒ–
```

## é…ç½®ç®¡ç†

### å·¥å…·é…ç½®
```toml
[tools]
auto_discover = true
plugin_directories = ["./plugins/tools", "./layers/rust/tools"]
security_checks = true
rate_limiting = true

[tools.execution]
timeout_default = 30
max_concurrent = 10
retry_attempts = 3
circuit_breaker_enabled = true

[tools.workflow]
max_execution_time = 300
max_parallel_branches = 5
state_persistence = true
event_logging = true

[tools.plugins.web_scraper]
enabled = true
rate_limit_per_minute = 60
user_agent = "Sira-Tool/1.0"

[tools.plugins.file_system]
enabled = true
allowed_paths = ["/tmp", "./data"]
max_file_size = 10485760

[tools.plugins.data_processor]
enabled = true
supported_formats = ["json", "csv", "xml"]
max_data_size = 52428800
```

### å·¥ä½œæµé…ç½®
```yaml
workflow:
  id: "data_processing_pipeline"
  name: "Data Processing Pipeline"
  version: "1.0.0"
  description: "Automated data processing workflow"

  triggers:
    - type: "schedule"
      cron: "0 */6 * * *"
    - type: "api"
      endpoint: "/api/workflows/data-processing"
    - type: "event"
      event_type: "data.uploaded"

  variables:
    input_file:
      type: "string"
      required: true
      description: "Input data file path"
    output_format:
      type: "enum"
      values: ["json", "csv", "xml"]
      default: "json"

  nodes:
    - id: "validate_input"
      type: "tool"
      tool_id: "file_validator"
      config:
        checks: ["exists", "readable", "format"]

    - id: "process_data"
      type: "tool"
      tool_id: "data_processor"
      config:
        processor: "transformer"
        mappings:
          - from: "input.data"
            to: "output.processed"

    - id: "store_result"
      type: "tool"
      tool_id: "file_writer"
      config:
        output_path: "${output_path}"
        format: "${output_format}"

  edges:
    - source: "validate_input"
      target: "process_data"
      condition: "result.valid == true"

    - source: "process_data"
      target: "store_result"
      condition: "result.success == true"
```

## æµ‹è¯•å’ŒéªŒè¯

### å·¥å…·æµ‹è¯•
```rust
#[cfg(test)]
mod tool_tests {
    use super::*;

    #[tokio::test]
    async fn test_web_scraper_tool() {
        let tool = WebScraperTool::new();
        let input = ToolInput::new(serde_json::json!({
            "url": "https://httpbin.org/html"
        }));

        let result = tool.execute(input).await.unwrap();
        assert!(result.output.get("content").is_some());
    }

    #[tokio::test]
    async fn test_file_system_tool() {
        let temp_dir = tempfile::tempdir().unwrap();
        let tool = FileSystemTool::new(vec![temp_dir.path().to_path_buf()]);

        // åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        let test_file = temp_dir.path().join("test.txt");
        tokio::fs::write(&test_file, "Hello, World!").await.unwrap();

        // æµ‹è¯•è¯»å–
        let input = ToolInput::new(serde_json::json!({
            "operation": "read",
            "path": test_file.to_str().unwrap()
        }));

        let result = tool.execute(input).await.unwrap();
        assert_eq!(result.output["content"], "Hello, World!");
    }
}
```

### å·¥ä½œæµæµ‹è¯•
```rust
#[cfg(test)]
mod workflow_tests {
    use super::*;

    #[tokio::test]
    async fn test_simple_workflow() {
        let engine = WorkflowEngine::new();

        // åˆ›å»ºç®€å•å·¥ä½œæµï¼šè¯»å–æ–‡ä»¶ -> å¤„ç†æ•°æ® -> ä¿å­˜ç»“æœ
        let workflow = Workflow {
            id: "test_workflow".to_string(),
            nodes: vec![
                WorkflowNode {
                    id: "read_file".to_string(),
                    node_type: NodeType::Tool,
                    data: NodeData {
                        tool_id: Some("file_reader".to_string()),
                        ..Default::default()
                    },
                    ..Default::default()
                },
                WorkflowNode {
                    id: "process_data".to_string(),
                    node_type: NodeType::Tool,
                    data: NodeData {
                        tool_id: Some("data_processor".to_string()),
                        ..Default::default()
                    },
                    ..Default::default()
                },
            ],
            edges: vec![
                WorkflowEdge {
                    source: "read_file".to_string(),
                    target: "process_data".to_string(),
                    ..Default::default()
                },
            ],
            ..Default::default()
        };

        let execution = WorkflowExecution {
            workflow_id: workflow.id.clone(),
            ..Default::default()
        };

        let result = engine.execute_workflow(execution).await.unwrap();
        assert_eq!(result.status, WorkflowStatus::Completed);
    }
}
```

## éƒ¨ç½²å’Œè¿ç»´

### å®¹å™¨åŒ–éƒ¨ç½²
```dockerfile
FROM rust:1.70-slim as builder
WORKDIR /app
COPY . .
RUN cargo build --release --bin sira-tools

FROM debian:bookworm-slim
RUN apt-get update && apt-get install -y ca-certificates libssl-dev
COPY --from=builder /app/target/release/sira-tools /usr/local/bin/

# åˆ›å»ºæ’ä»¶ç›®å½•
RUN mkdir -p /app/plugins
VOLUME ["/app/plugins"]

EXPOSE 9092
CMD ["sira-tools"]
```

### æ’ä»¶ç®¡ç†
- æ’ä»¶ç‰ˆæœ¬æ§åˆ¶
- ä¾èµ–å…³ç³»è§£æ
- å®‰å…¨æ²™ç®±æ‰§è¡Œ
- æ€§èƒ½ç›‘æ§å’Œé™åˆ¶
- è‡ªåŠ¨æ›´æ–°æœºåˆ¶

### ç›‘æ§å‘Šè­¦
- å·¥å…·æ‰§è¡ŒæŒ‡æ ‡
- å·¥ä½œæµæˆåŠŸç‡
- æ€§èƒ½ç“¶é¢ˆè¯†åˆ«
- é”™è¯¯ç‡ç›‘æ§
- èµ„æºä½¿ç”¨å‘Šè­¦

## å®‰å…¨è€ƒè™‘

### å·¥å…·å®‰å…¨
- æƒé™æ§åˆ¶å’Œè®¿é—®é™åˆ¶
- è¾“å…¥éªŒè¯å’Œæ¸…ç†
- èµ„æºä½¿ç”¨é™åˆ¶
- æ‰§è¡Œè¶…æ—¶ä¿æŠ¤
- å®¡è®¡æ—¥å¿—è®°å½•

### å·¥ä½œæµå®‰å…¨
- å·¥ä½œæµéªŒè¯å’Œç­¾å
- æ‰§è¡Œæƒé™æ£€æŸ¥
- æ•°æ®éš”ç¦»å’Œä¿æŠ¤
- å¼‚å¸¸å¤„ç†å’Œæ¢å¤
- å®‰å…¨äº‹ä»¶ç›‘æ§

## æ‰©å±•æœºåˆ¶

### è‡ªå®šä¹‰å·¥å…·å¼€å‘
```rust
#[derive(Debug)]
pub struct CustomTool {
    config: CustomToolConfig,
}

#[async_trait]
impl Tool for CustomTool {
    fn metadata(&self) -> ToolMetadata {
        ToolMetadata {
            id: "custom_tool".to_string(),
            name: "Custom Tool".to_string(),
            category: ToolCategory::Custom("business".to_string()),
            description: "Custom business logic tool".to_string(),
            ..Default::default()
        }
    }

    async fn execute(&self, input: ToolInput) -> Result<ToolOutput, ToolError> {
        // è‡ªå®šä¹‰å·¥å…·é€»è¾‘
        let result = self.perform_custom_operation(input).await?;
        Ok(ToolOutput::new(result))
    }
}

// ç¼–è¯‘ä¸ºåŠ¨æ€åº“
#[no_mangle]
pub extern "C" fn create_tool() -> *mut dyn Tool {
    let tool = CustomTool::new();
    Box::into_raw(Box::new(tool)) as *mut dyn Tool
}

#[no_mangle]
pub extern "C" fn tool_metadata() -> ToolMetadata {
    CustomTool::new().metadata()
}
```

### å·¥ä½œæµæ¨¡æ¿
```rust
pub struct WorkflowTemplate {
    pub name: String,
    pub description: String,
    pub category: String,
    pub parameters: Vec<TemplateParameter>,
    pub nodes: Vec<WorkflowNode>,
    pub edges: Vec<WorkflowEdge>,
}

impl WorkflowTemplate {
    pub fn instantiate(&self, parameters: HashMap<String, serde_json::Value>) -> Result<Workflow, TemplateError> {
        // å‚æ•°æ›¿æ¢
        let mut workflow = Workflow {
            id: format!("{}_{}", self.name, Utc::now().timestamp()),
            name: self.name.clone(),
            description: self.description.clone(),
            nodes: self.nodes.clone(),
            edges: self.edges.clone(),
            ..Default::default()
        };

        // åº”ç”¨å‚æ•°
        self.apply_parameters(&mut workflow, parameters)?;

        Ok(workflow)
    }
}
```

## æœªæ¥è§„åˆ’

### ğŸš€ å¢å¼ºåŠŸèƒ½
- [ ] å›¾å½¢åŒ–å·¥ä½œæµç¼–è¾‘å™¨
- [ ] AIé©±åŠ¨çš„å·¥ä½œæµä¼˜åŒ–
- [ ] å®æ—¶åä½œå·¥ä½œæµ
- [ ] å·¥ä½œæµç‰ˆæœ¬æ§åˆ¶
- [ ] äº‘åŸç”Ÿå·¥ä½œæµç¼–æ’

### ğŸ”Œ æ’ä»¶ç”Ÿæ€
- [ ] æ’ä»¶å¸‚åœºå’Œå•†åº—
- [ ] æ’ä»¶ä½¿ç”¨ç»Ÿè®¡
- [ ] æ’ä»¶è¯„çº§å’Œè¯„è®º
- [ ] æ’ä»¶è‡ªåŠ¨æ›´æ–°
- [ ] ç¬¬ä¸‰æ–¹æ’ä»¶é›†æˆ

### ğŸ¤– æ™ºèƒ½å·¥å…·
- [ ] AIç”Ÿæˆçš„å·¥ä½œæµ
- [ ] å·¥å…·æ¨èç³»ç»Ÿ
- [ ] è‡ªåŠ¨åŒ–å·¥å…·å‘ç°
- [ ] æ™ºèƒ½å·¥å…·ç»„åˆ
- [ ] å·¥å…·æ€§èƒ½ä¼˜åŒ–

---

**Sira Tools** - è®©AIæ‹¥æœ‰æ‰§è¡Œèƒ½åŠ›çš„å·¥å…·ç”Ÿæ€ç³»ç»Ÿ
