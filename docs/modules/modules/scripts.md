# ğŸ“œ Scripts è„šæœ¬å·¥å…·æ¨¡å—

## ğŸ“‹ æ¦‚è¿°

Scriptsæ¨¡å—æä¾›äº†å…¨é¢çš„è¿ç»´è„šæœ¬å·¥å…·é›†ï¼Œæ”¯æŒæ€§èƒ½æµ‹è¯•ã€éƒ¨ç½²ç®¡ç†ã€ç³»ç»Ÿç›‘æ§å’Œç»´æŠ¤æ“ä½œã€‚è¯¥æ¨¡å—é‡‡ç”¨Shellè„šæœ¬å’ŒNode.jsè„šæœ¬ç›¸ç»“åˆçš„æ–¹å¼ï¼Œå®ç°äº†ä»å¼€å‘åˆ°ç”Ÿäº§çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚

## ğŸ—ï¸ æ¶æ„ç»„æˆ

```
scripts/
â”œâ”€â”€ benchmark-performance.sh    # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”œâ”€â”€ deploy-production.sh        # ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
â”œâ”€â”€ deploy-staging.sh          # Stagingç¯å¢ƒéƒ¨ç½²
â”œâ”€â”€ monitor-system.sh          # ç³»ç»Ÿç›‘æ§è„šæœ¬ (451è¡Œ)
â”œâ”€â”€ run-regression-tests.sh    # å›å½’æµ‹è¯•æ‰§è¡Œ
â”œâ”€â”€ test-integrations.sh       # é›†æˆæµ‹è¯•è„šæœ¬
â””â”€â”€ ai-gateway/                # AIç½‘å…³ä¸“ç”¨è„šæœ¬ç›®å½•
    â”œâ”€â”€ benchmark-performance.sh
    â”œâ”€â”€ deploy-production.sh
    â”œâ”€â”€ deploy-staging.sh
    â”œâ”€â”€ monitor-system.sh
    â”œâ”€â”€ run-regression-tests.sh
    â””â”€â”€ test-integrations.sh
```

## ğŸš€ æ ¸å¿ƒè„šæœ¬è¯¦è§£

### 1. ç³»ç»Ÿç›‘æ§è„šæœ¬ (monitor-system.sh)

**åŠŸèƒ½ç‰¹æ€§**:
- ğŸ” å®æ—¶ç³»ç»Ÿèµ„æºç›‘æ§
- ğŸ“Š æ€§èƒ½æŒ‡æ ‡æ”¶é›†
- ğŸš¨ å¼‚å¸¸å‘Šè­¦æ£€æµ‹
- ğŸ“ˆ è¶‹åŠ¿åˆ†ææŠ¥å‘Š
- ğŸ’¾ æ—¥å¿—è½®è½¬ç®¡ç†

**ç›‘æ§æŒ‡æ ‡**:
```bash
#!/bin/bash

# CPUä½¿ç”¨ç‡ç›‘æ§
monitor_cpu() {
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1}')
    echo "CPU Usage: ${cpu_usage}%"

    if (( $(echo "$cpu_usage > 90" | bc -l) )); then
        alert "HIGH CPU USAGE" "CPU usage is ${cpu_usage}%"
    fi
}

# å†…å­˜ä½¿ç”¨ç›‘æ§
monitor_memory() {
    local mem_info=$(free | grep Mem)
    local total=$(echo $mem_info | awk '{print $2}')
    local used=$(echo $mem_info | awk '{print $3}')
    local usage_percent=$(( used * 100 / total ))

    echo "Memory Usage: ${usage_percent}% (${used}KB/${total}KB)"

    if [ $usage_percent -gt 90 ]; then
        alert "HIGH MEMORY USAGE" "Memory usage is ${usage_percent}%"
    fi
}

# ç£ç›˜ä½¿ç”¨ç›‘æ§
monitor_disk() {
    local disk_usage=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')

    if [ $disk_usage -gt 90 ]; then
        alert "HIGH DISK USAGE" "Disk usage is ${disk_usage}%"
    fi
}

# ç½‘ç»œè¿æ¥ç›‘æ§
monitor_network() {
    local connections=$(netstat -tun | grep ESTABLISHED | wc -l)
    echo "Active connections: $connections"

    if [ $connections -gt 1000 ]; then
        alert "HIGH NETWORK CONNECTIONS" "$connections active connections"
    fi
}

# æœåŠ¡å¥åº·æ£€æŸ¥
monitor_services() {
    local services=("ai-gateway" "kong" "redis" "nats" "prometheus")

    for service in "${services[@]}"; do
        if docker-compose ps $service | grep -q "Up"; then
            echo "âœ… $service is running"
        else
            alert "SERVICE DOWN" "$service is not running"
        fi
    done
}

# AIç½‘å…³ç‰¹å®šç›‘æ§
monitor_ai_gateway() {
    # APIå“åº”æ—¶é—´ç›‘æ§
    local response_time=$(curl -o /dev/null -s -w "%{time_total}" http://localhost:8080/health)
    echo "Sira response time: ${response_time}s"

    if (( $(echo "$response_time > 5.0" | bc -l) )); then
        alert "SLOW RESPONSE" "Sira response time: ${response_time}s"
    fi

    # ç¼“å­˜å‘½ä¸­ç‡ç›‘æ§
    local cache_stats=$(curl -s http://localhost:8080/cache/stats)
    local hit_ratio=$(echo $cache_stats | jq '.hit_ratio')

    if (( $(echo "$hit_ratio < 0.8" | bc -l) )); then
        alert "LOW CACHE HIT RATIO" "Cache hit ratio: $hit_ratio"
    fi
}

# PrometheusæŒ‡æ ‡æ”¶é›†
collect_metrics() {
    local timestamp=$(date +%s)

    # ç³»ç»ŸæŒ‡æ ‡
    echo "system_cpu_usage $cpu_usage $timestamp" >> metrics.txt
    echo "system_memory_usage $usage_percent $timestamp" >> metrics.txt

    # åº”ç”¨æŒ‡æ ‡
    echo "ai_gateway_response_time $response_time $timestamp" >> metrics.txt
    echo "ai_gateway_cache_hit_ratio $hit_ratio $timestamp" >> metrics.txt
}

# å‘Šè­¦å‡½æ•°
alert() {
    local subject="$1"
    local message="$2"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')

    echo "[$timestamp] ALERT: $subject - $message" >> alerts.log

    # å‘é€é‚®ä»¶å‘Šè­¦ (å¯é€‰)
    if [ -n "$ALERT_EMAIL" ]; then
        echo "$message" | mail -s "Sira Alert: $subject" "$ALERT_EMAIL"
    fi

    # å‘é€Slackå‘Šè­¦ (å¯é€‰)
    if [ -n "$SLACK_WEBHOOK" ]; then
        curl -X POST -H 'Content-type: application/json' \
             --data "{\"text\":\"Sira Alert: $subject - $message\"}" \
             "$SLACK_WEBHOOK"
    fi
}

# ä¸»ç›‘æ§å¾ªç¯
main() {
    echo "Starting Sira monitoring system..."
    echo "Press Ctrl+C to stop"

    while true; do
        echo "=== $(date) ==="

        monitor_cpu
        monitor_memory
        monitor_disk
        monitor_network
        monitor_services
        monitor_ai_gateway

        collect_metrics

        echo "Monitoring cycle completed. Sleeping for 60 seconds..."
        sleep 60
    done
}

# å‚æ•°å¤„ç†
case "$1" in
    "cpu") monitor_cpu ;;
    "memory") monitor_memory ;;
    "disk") monitor_disk ;;
    "network") monitor_network ;;
    "services") monitor_services ;;
    "ai-gateway") monitor_ai_gateway ;;
    *) main ;;
esac
```

### 2. éƒ¨ç½²è„šæœ¬

#### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½² (deploy-production.sh)

**éƒ¨ç½²æµç¨‹**:
```bash
#!/bin/bash

# éƒ¨ç½²å‰ç½®æ£€æŸ¥
pre_deploy_check() {
    echo "ğŸ” æ‰§è¡Œéƒ¨ç½²å‰ç½®æ£€æŸ¥..."

    # æ£€æŸ¥DockerçŠ¶æ€
    if ! docker info > /dev/null 2>&1; then
        echo "âŒ Dockeræœªè¿è¡Œ"
        exit 1
    fi

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if [ -z "$OPENAI_API_KEY" ]; then
        echo "âŒ OPENAI_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®"
        exit 1
    fi

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if [ ! -f "docker/production/docker-compose.yml" ]; then
        echo "âŒ ç”Ÿäº§ç¯å¢ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨"
        exit 1
    fi

    echo "âœ… å‰ç½®æ£€æŸ¥é€šè¿‡"
}

# å¤‡ä»½å½“å‰éƒ¨ç½²
backup_current_deployment() {
    echo "ğŸ’¾ å¤‡ä»½å½“å‰éƒ¨ç½²..."

    local backup_dir="backups/$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$backup_dir"

    # å¤‡ä»½é…ç½®æ–‡ä»¶
    cp docker/production/docker-compose.yml "$backup_dir/"

    # å¤‡ä»½ç¯å¢ƒå˜é‡
    cp .env "$backup_dir/" 2>/dev/null || true

    # å¤‡ä»½æ•°æ®å· (å¦‚æœéœ€è¦)
    docker run --rm -v ai-gateway_prometheus_data:/data \
           -v "$backup_dir":/backup alpine \
           tar czf /backup/prometheus-backup.tar.gz -C /data .

    echo "âœ… å¤‡ä»½å®Œæˆ: $backup_dir"
}

# éƒ¨ç½²æ–°ç‰ˆæœ¬
deploy_new_version() {
    echo "ğŸš€ éƒ¨ç½²æ–°ç‰ˆæœ¬..."

    # æ‹‰å–æœ€æ–°é•œåƒ
    docker-compose -f docker/production/docker-compose.yml pull

    # æ»šåŠ¨æ›´æ–°æœåŠ¡
    docker-compose -f docker/production/docker-compose.yml up -d \
                   --scale ai-gateway=2 \
                   --no-deps ai-gateway

    # ç­‰å¾…å¥åº·æ£€æŸ¥
    echo "â³ ç­‰å¾…æœåŠ¡å°±ç»ª..."
    sleep 30

    # éªŒè¯éƒ¨ç½²
    if curl -f http://localhost:8080/health > /dev/null 2>&1; then
        echo "âœ… éƒ¨ç½²æˆåŠŸ"

        # ç¼©æ”¾åˆ°æ­£å¸¸å®ä¾‹æ•°
        docker-compose -f docker/production/docker-compose.yml up -d \
                       --scale ai-gateway=1
    else
        echo "âŒ éƒ¨ç½²å¤±è´¥ï¼Œæ‰§è¡Œå›æ»š..."
        rollback_deployment
        exit 1
    fi
}

# å›æ»šéƒ¨ç½²
rollback_deployment() {
    echo "ğŸ”„ æ‰§è¡Œå›æ»š..."

    # åœæ­¢å½“å‰æœåŠ¡
    docker-compose -f docker/production/docker-compose.yml down

    # æ¢å¤å¤‡ä»½
    if [ -d "backups/latest" ]; then
        cp backups/latest/docker-compose.yml docker/production/
        cp backups/latest/.env .env 2>/dev/null || true
    fi

    # é‡å¯æœåŠ¡
    docker-compose -f docker/production/docker-compose.yml up -d

    echo "âœ… å›æ»šå®Œæˆ"
}

# éƒ¨ç½²åéªŒè¯
post_deploy_verification() {
    echo "ğŸ” æ‰§è¡Œéƒ¨ç½²åéªŒè¯..."

    # å¥åº·æ£€æŸ¥
    if ! curl -f http://localhost:8080/health > /dev/null 2>&1; then
        echo "âŒ å¥åº·æ£€æŸ¥å¤±è´¥"
        return 1
    fi

    # APIåŠŸèƒ½æµ‹è¯•
    local test_response=$(curl -s -X POST http://localhost:8080/api/v1/ai/chat/completions \
                         -H "Content-Type: application/json" \
                         -H "x-api-key: test-key" \
                         -d '{"model":"gpt-3.5-turbo","messages":[{"role":"user","content":"test"}]}')

    if echo "$test_response" | jq -e '.error' > /dev/null 2>&1; then
        echo "âŒ APIåŠŸèƒ½æµ‹è¯•å¤±è´¥"
        return 1
    fi

    # ç›‘æ§æœåŠ¡æ£€æŸ¥
    if ! curl -f http://localhost:9090/-/healthy > /dev/null 2>&1; then
        echo "âŒ Prometheuså¥åº·æ£€æŸ¥å¤±è´¥"
        return 1
    fi

    echo "âœ… éƒ¨ç½²åéªŒè¯é€šè¿‡"
}

# ä¸»éƒ¨ç½²æµç¨‹
main() {
    echo "ğŸ—ï¸  å¼€å§‹Siraç”Ÿäº§ç¯å¢ƒéƒ¨ç½²"

    pre_deploy_check
    backup_current_deployment
    deploy_new_version

    if post_deploy_verification; then
        echo "ğŸ‰ éƒ¨ç½²æˆåŠŸå®Œæˆ"
        update_latest_backup
    else
        echo "ğŸ’¥ éƒ¨ç½²éªŒè¯å¤±è´¥"
        exit 1
    fi
}

# å‚æ•°å¤„ç†
case "$1" in
    "check") pre_deploy_check ;;
    "backup") backup_current_deployment ;;
    "rollback") rollback_deployment ;;
    "verify") post_deploy_verification ;;
    *) main ;;
esac
```

#### Stagingç¯å¢ƒéƒ¨ç½² (deploy-staging.sh)

**è½»é‡çº§éƒ¨ç½²**:
```bash
#!/bin/bash

# Stagingç¯å¢ƒå¿«é€Ÿéƒ¨ç½²
deploy_staging() {
    echo "ğŸš€ éƒ¨ç½²åˆ°Stagingç¯å¢ƒ..."

    cd docker/staging

    # æ„å»ºé•œåƒ
    docker-compose build --no-cache

    # éƒ¨ç½²æœåŠ¡
    docker-compose up -d

    # è¿è¡Œé›†æˆæµ‹è¯•
    docker-compose exec ai-gateway npm run test:integration

    echo "âœ… Stagingéƒ¨ç½²å®Œæˆ"
}
```

### 3. æ€§èƒ½æµ‹è¯•è„šæœ¬ (benchmark-performance.sh)

**ç»¼åˆæ€§èƒ½è¯„ä¼°**:
```bash
#!/bin/bash

# æ€§èƒ½åŸºå‡†æµ‹è¯•é…ç½®
TEST_DURATION=300          # æµ‹è¯•æ—¶é•¿(ç§’)
CONCURRENT_USERS=50        # å¹¶å‘ç”¨æˆ·æ•°
RAMP_UP_TIME=30           # çˆ¬å¡æ—¶é—´(ç§’)
API_ENDPOINT="http://localhost:8080/api/v1/ai/chat/completions"

# æµ‹è¯•åœºæ™¯
TEST_SCENARIOS=(
    "light:10:5"          # è½»è´Ÿè½½: 10å¹¶å‘, 5ç§’æŒç»­
    "medium:50:30"        # ä¸­è´Ÿè½½: 50å¹¶å‘, 30ç§’æŒç»­
    "heavy:100:60"        # é‡è´Ÿè½½: 100å¹¶å‘, 60ç§’æŒç»­
    "spike:200:10"        # å³°å€¼è´Ÿè½½: 200å¹¶å‘, 10ç§’æŒç»­
)

# AIè¯·æ±‚è´Ÿè½½
AI_REQUESTS=(
    '{"model":"gpt-3.5-turbo","messages":[{"role":"user","content":"Hello"}]}'
    '{"model":"gpt-4","messages":[{"role":"user","content":"Explain quantum computing"}]}'
    '{"model":"claude-3-haiku","messages":[{"role":"user","content":"Write a short story"}]}'
)

# è¿è¡Œæ€§èƒ½æµ‹è¯•
run_performance_test() {
    local scenario=$1
    local concurrency=$2
    local duration=$3

    echo "ğŸƒ è¿è¡Œæ€§èƒ½æµ‹è¯•åœºæ™¯: $scenario"
    echo "å¹¶å‘æ•°: $concurrency, æŒç»­æ—¶é—´: ${duration}ç§’"

    # ä½¿ç”¨Apache Benchè¿›è¡Œæµ‹è¯•
    ab -n $((concurrency * duration)) \
       -c $concurrency \
       -T "application/json" \
       -H "x-api-key: benchmark-key" \
       -p ai_request.json \
       "$API_ENDPOINT" \
       > "results/${scenario}.txt"

    # åˆ†æç»“æœ
    analyze_results "results/${scenario}.txt"
}

# åˆ†ææµ‹è¯•ç»“æœ
analyze_results() {
    local result_file=$1

    echo "ğŸ“Š åˆ†ææµ‹è¯•ç»“æœ: $result_file"

    # æå–å…³é”®æŒ‡æ ‡
    local requests_per_sec=$(grep "Requests per second" "$result_file" | awk '{print $4}')
    local time_per_request=$(grep "Time per request.*mean" "$result_file" | awk '{print $4}')
    local transfer_rate=$(grep "Transfer rate" "$result_file" | awk '{print $3}')

    echo "è¯·æ±‚/ç§’: $requests_per_sec"
    echo "å¹³å‡å“åº”æ—¶é—´: ${time_per_request}ms"
    echo "ä¼ è¾“é€Ÿç‡: ${transfer_rate}KB/s"

    # æ€§èƒ½è¯„ä¼°
    if (( $(echo "$time_per_request > 2000" | bc -l) )); then
        echo "âš ï¸  å“åº”æ—¶é—´è¿‡é•¿ (>2ç§’)"
    fi

    if (( $(echo "$requests_per_sec < 10" | bc -l) )); then
        echo "âš ï¸  ååé‡è¾ƒä½ (<10 req/s)"
    fi
}

# ç³»ç»Ÿèµ„æºç›‘æ§
monitor_resources() {
    echo "ğŸ” ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ..."

    # CPUä½¿ç”¨ç‡
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1}')

    # å†…å­˜ä½¿ç”¨ç‡
    local mem_usage=$(free | grep Mem | awk '{printf "%.2f", $3/$2 * 100.0}')

    # ç£ç›˜I/O
    local disk_io=$(iostat -d 1 1 | grep sda | awk '{print $2}')

    echo "CPUä½¿ç”¨ç‡: ${cpu_usage}%"
    echo "å†…å­˜ä½¿ç”¨ç‡: ${mem_usage}%"
    echo "ç£ç›˜I/O: ${disk_io} KB/s"
}

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
generate_report() {
    echo "ğŸ“‹ ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š..."

    cat > performance-report.html << EOF
<!DOCTYPE html>
<html>
<head>
    <title>Siraæ€§èƒ½æµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .metric { background: #f5f5f5; padding: 10px; margin: 10px 0; }
        .warning { color: #ff6b35; }
        .success { color: #4caf50; }
    </style>
</head>
<body>
    <h1>Siraæ€§èƒ½æµ‹è¯•æŠ¥å‘Š</h1>
    <p>æµ‹è¯•æ—¶é—´: $(date)</p>

    <h2>æµ‹è¯•ç»“æœæ‘˜è¦</h2>
    $(for result in results/*.txt; do
        echo "<div class='metric'>"
        echo "<h3>$(basename "$result" .txt)</h3>"
        grep -E "(Requests per second|Time per request|Transfer rate)" "$result" | \
        sed 's/^/    /'
        echo "</div>"
    done)

    <h2>ç³»ç»Ÿèµ„æº</h2>
    <div class='metric'>
        <p>CPUä½¿ç”¨ç‡: ${cpu_usage}%</p>
        <p>å†…å­˜ä½¿ç”¨ç‡: ${mem_usage}%</p>
        <p>ç£ç›˜I/O: ${disk_io} KB/s</p>
    </div>
</body>
</html>
EOF

    echo "âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ: performance-report.html"
}

# ä¸»æµ‹è¯•æµç¨‹
main() {
    echo "ğŸ§ª å¼€å§‹Siraæ€§èƒ½æµ‹è¯•"

    mkdir -p results

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    echo "$AI_REQUESTS" | jq -r '.[0]' > ai_request.json

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯
    for scenario in "${TEST_SCENARIOS[@]}"; do
        IFS=':' read -r name concurrency duration <<< "$scenario"
        run_performance_test "$name" "$concurrency" "$duration"
        sleep 10  # åœºæ™¯é—´ä¼‘æ¯
    done

    # ç›‘æ§èµ„æºä½¿ç”¨
    monitor_resources

    # ç”ŸæˆæŠ¥å‘Š
    generate_report

    echo "ğŸ¯ æ€§èƒ½æµ‹è¯•å®Œæˆ"
}

# å‚æ•°å¤„ç†
case "$1" in
    "light") run_performance_test "light" 10 5 ;;
    "medium") run_performance_test "medium" 50 30 ;;
    "heavy") run_performance_test "heavy" 100 60 ;;
    "monitor") monitor_resources ;;
    "report") generate_report ;;
    *) main ;;
esac
```

### 4. å›å½’æµ‹è¯•è„šæœ¬ (run-regression-tests.sh)

**è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•**:
```bash
#!/bin/bash

# å›å½’æµ‹è¯•é…ç½®
TEST_CATEGORIES=(
    "unit:å•å…ƒæµ‹è¯•"
    "integration:é›†æˆæµ‹è¯•"
    "e2e:ç«¯åˆ°ç«¯æµ‹è¯•"
    "performance:æ€§èƒ½æµ‹è¯•"
    "security:å®‰å…¨æµ‹è¯•"
)

# å†å²åŸºå‡†æ•°æ®
BASELINE_FILE="regression-baseline.json"

# è¿è¡Œå›å½’æµ‹è¯•
run_regression_tests() {
    echo "ğŸ”„ æ‰§è¡Œå›å½’æµ‹è¯•..."

    local results=()
    local failed_categories=()

    for category in "${TEST_CATEGORIES[@]}"; do
        IFS=':' read -r test_type display_name <<< "$category"

        echo "æµ‹è¯•ç±»åˆ«: $display_name"

        case $test_type in
            "unit")
                npm run test:unit > "results/unit.log" 2>&1
                ;;
            "integration")
                npm run test:integration > "results/integration.log" 2>&1
                ;;
            "e2e")
                npm run test:e2e > "results/e2e.log" 2>&1
                ;;
            "performance")
                ./scripts/benchmark-performance.sh medium > "results/performance.log" 2>&1
                ;;
            "security")
                npm run test:security > "results/security.log" 2>&1
                ;;
        esac

        local exit_code=$?
        results+=("$test_type:$exit_code")

        if [ $exit_code -ne 0 ]; then
            failed_categories+=("$display_name")
            echo "âŒ $display_name å¤±è´¥"
        else
            echo "âœ… $display_name é€šè¿‡"
        fi
    done

    # ä¿å­˜ç»“æœ
    echo "${results[@]}" > regression-results.txt

    # æŠ¥å‘Šå¤±è´¥çš„ç±»åˆ«
    if [ ${#failed_categories[@]} -ne 0 ]; then
        echo "ğŸ’¥ ä»¥ä¸‹æµ‹è¯•ç±»åˆ«å¤±è´¥:"
        printf '%s\n' "${failed_categories[@]}"
        return 1
    fi

    echo "âœ… æ‰€æœ‰å›å½’æµ‹è¯•é€šè¿‡"
}

# ä¸åŸºå‡†æ¯”è¾ƒ
compare_with_baseline() {
    echo "ğŸ“Š ä¸åŸºå‡†æ¯”è¾ƒ..."

    if [ ! -f "$BASELINE_FILE" ]; then
        echo "âš ï¸  åŸºå‡†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„åŸºå‡†"
        cp regression-results.txt "$BASELINE_FILE"
        return 0
    fi

    local baseline_results=($(cat "$BASELINE_FILE"))
    local current_results=($(cat regression-results.txt))

    local regressions=()

    for i in "${!current_results[@]}"; do
        IFS=':' read -r test_type current_code <<< "${current_results[$i]}"
        IFS=':' read -r baseline_type baseline_code <<< "${baseline_results[$i]}"

        if [ "$current_code" != "$baseline_code" ] && [ "$baseline_code" == "0" ]; then
            regressions+=("$test_type ä»é€šè¿‡å˜ä¸ºå¤±è´¥")
        fi
    done

    if [ ${#regressions[@]} -ne 0 ]; then
        echo "âš ï¸  å‘ç°å›å½’:"
        printf '%s\n' "${regressions[@]}"
        return 1
    fi

    echo "âœ… æ— æ€§èƒ½å›å½’"
}

# ç”Ÿæˆå›å½’æŠ¥å‘Š
generate_regression_report() {
    echo "ğŸ“‹ ç”Ÿæˆå›å½’æµ‹è¯•æŠ¥å‘Š..."

    cat > regression-report.md << EOF
# Siraå›å½’æµ‹è¯•æŠ¥å‘Š

**æµ‹è¯•æ—¶é—´**: $(date)
**æµ‹è¯•ç¯å¢ƒ**: $(hostname)

## æµ‹è¯•ç»“æœ

| æµ‹è¯•ç±»åˆ« | çŠ¶æ€ | è¯¦æƒ… |
|----------|------|------|
EOF

    local current_results=($(cat regression-results.txt))

    for result in "${current_results[@]}"; do
        IFS=':' read -r test_type exit_code <<< "$result"

        local status="âœ… é€šè¿‡"
        if [ "$exit_code" != "0" ]; then
            status="âŒ å¤±è´¥"
        fi

        local display_name=""
        for category in "${TEST_CATEGORIES[@]}"; do
            IFS=':' read -r cat_type cat_name <<< "$category"
            if [ "$cat_type" == "$test_type" ]; then
                display_name="$cat_name"
                break
            fi
        done

        echo "| $display_name | $status | [æŸ¥çœ‹æ—¥å¿—](results/${test_type}.log) |" >> regression-report.md
    done

    echo "" >> regression-report.md
    echo "## å›å½’åˆ†æ" >> regression-report.md

    if compare_with_baseline 2>/dev/null; then
        echo "âœ… ä¸åŸºå‡†ç›¸æ¯”æ— æ˜¾è‘—å›å½’" >> regression-report.md
    else
        echo "âš ï¸  å‘ç°æ€§èƒ½å›å½’ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°å¤±è´¥çš„æµ‹è¯•" >> regression-report.md
    fi

    echo "âœ… å›å½’æŠ¥å‘Šç”Ÿæˆå®Œæˆ: regression-report.md"
}

# ä¸»å›å½’æµ‹è¯•æµç¨‹
main() {
    echo "ğŸ”„ å¼€å§‹Siraå›å½’æµ‹è¯•"

    mkdir -p results

    if run_regression_tests; then
        compare_with_baseline
        generate_regression_report
        echo "ğŸ‰ å›å½’æµ‹è¯•å®Œæˆ"
    else
        echo "ğŸ’¥ å›å½’æµ‹è¯•å¤±è´¥"
        exit 1
    fi
}

# å‚æ•°å¤„ç†
case "$1" in
    "unit") npm run test:unit ;;
    "integration") npm run test:integration ;;
    "e2e") npm run test:e2e ;;
    "performance") ./scripts/benchmark-performance.sh medium ;;
    "security") npm run test:security ;;
    "compare") compare_with_baseline ;;
    "report") generate_regression_report ;;
    *) main ;;
esac
```

## ğŸ“Š è„šæœ¬ç»Ÿè®¡ä¿¡æ¯

| è„šæœ¬åç§° | ä»£ç è¡Œæ•° | åŠŸèƒ½æè¿° | æ‰§è¡Œé¢‘ç‡ |
|----------|----------|----------|----------|
| monitor-system.sh | 451è¡Œ | å…¨é¢ç³»ç»Ÿç›‘æ§ | æŒç»­è¿è¡Œ |
| deploy-production.sh | 180è¡Œ | ç”Ÿäº§ç¯å¢ƒéƒ¨ç½² | æŒ‰éœ€æ‰§è¡Œ |
| benchmark-performance.sh | 220è¡Œ | æ€§èƒ½åŸºå‡†æµ‹è¯• | å®šæœŸæ‰§è¡Œ |
| run-regression-tests.sh | 160è¡Œ | å›å½’æµ‹è¯•æ‰§è¡Œ | CI/CDé›†æˆ |
| test-integrations.sh | 120è¡Œ | é›†æˆæµ‹è¯•è„šæœ¬ | CI/CDé›†æˆ |
| deploy-staging.sh | 80è¡Œ | Stagingéƒ¨ç½² | å¼€å‘æµç¨‹ |

## ğŸ”— ç›¸å…³é“¾æ¥

- **[ä¸»README](../README.md)** - é¡¹ç›®æ€»è§ˆ
- **[éƒ¨ç½²æŒ‡å—](../DEPLOYMENT-GUIDE.md)** - è¯¦ç»†éƒ¨ç½²è¯´æ˜
- **[ç›‘æ§é…ç½®](../README-AI.md#ç›‘æ§)** - å¯è§‚æµ‹æ€§é…ç½®
- **[æµ‹è¯•è¿è¡Œ](../README-AI.md#æµ‹è¯•)** - æµ‹è¯•æ‰§è¡ŒæŒ‡å—

## ğŸ¤ ä½¿ç”¨æŒ‡å—

### 1. ç›‘æ§ç³»ç»Ÿå¯åŠ¨
```bash
# åå°è¿è¡Œç›‘æ§
nohup ./scripts/monitor-system.sh > monitor.log 2>&1 &

# æŸ¥çœ‹ç›‘æ§çŠ¶æ€
tail -f monitor.log
```

### 2. è‡ªåŠ¨åŒ–éƒ¨ç½²
```bash
# ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
./scripts/deploy-production.sh

# ä»…æ‰§è¡Œéƒ¨ç½²éªŒè¯
./scripts/deploy-production.sh verify
```

### 3. æ€§èƒ½è¯„ä¼°
```bash
# å®Œæ•´æ€§èƒ½æµ‹è¯•å¥—ä»¶
./scripts/benchmark-performance.sh

# ç‰¹å®šè´Ÿè½½æµ‹è¯•
./scripts/benchmark-performance.sh heavy
```

### 4. å›å½’æµ‹è¯•
```bash
# å®Œæ•´å›å½’æµ‹è¯•
./scripts/run-regression-tests.sh

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
./scripts/run-regression-tests.sh report
```

---

*æœ€åæ›´æ–°: 2025å¹´11æœˆ7æ—¥* | ğŸ”™ [è¿”å›æ¨¡å—åˆ—è¡¨](../README.md#æ¨¡å—å¯¼èˆª)
