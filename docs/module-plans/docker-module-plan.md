# ğŸ³ éƒ¨ç½²æ¨¡å— (Docker Module) è¯¦ç»†è§„åˆ’

## ğŸ“‹ æ¨¡å—æ¦‚è¿°

**éƒ¨ç½²æ¨¡å—** æ˜¯Sira AIç½‘å…³çš„"åŸºç¡€è®¾æ–½å¼•æ“"ï¼ŒåŸºäºDockerå’Œå®¹å™¨åŒ–æŠ€æœ¯ï¼Œæä¾›å®Œæ•´çš„éƒ¨ç½²ã€ç¼–æ’ã€ç›‘æ§å’Œè¿ç»´è§£å†³æ–¹æ¡ˆã€‚å®ƒæ˜¯ç³»ç»Ÿçš„è¿è¡ŒåŸºç¡€ï¼Œç¡®ä¿åº”ç”¨èƒ½å¤Ÿåœ¨å„ç§ç¯å¢ƒä¸­ç¨³å®šã€é«˜æ•ˆåœ°è¿è¡Œã€‚

### å®šä½ä¸èŒè´£

- **ç³»ç»Ÿå®šä½**: å®¹å™¨åŒ–éƒ¨ç½²å’ŒåŸºç¡€è®¾æ–½ç®¡ç†çš„æ ¸å¿ƒå¹³å°
- **ä¸»è¦èŒè´£**: å®¹å™¨åŒ–ã€ç¼–æ’éƒ¨ç½²ã€ç¯å¢ƒç®¡ç†ã€ç›‘æ§è¿ç»´
- **è®¾è®¡ç†å¿µ**: äº‘åŸç”Ÿã€è‡ªåŠ¨åŒ–ã€å¯æ‰©å±•ã€å®‰å…¨å¯é 

### æ¶æ„å±‚æ¬¡

```
éƒ¨ç½²æ¨¡å—æ¶æ„:
â”œâ”€â”€ ğŸ—ï¸ å®¹å™¨åŒ–å±‚ (Containerization Layer)
â”‚   â”œâ”€â”€ Dockeré•œåƒæ„å»º (Image Building)
â”‚   â”œâ”€â”€ å¤šé˜¶æ®µæ„å»º (Multi-stage Build)
â”‚   â”œâ”€â”€ é•œåƒä¼˜åŒ– (Image Optimization)
â”‚   â””â”€â”€ å®‰å…¨åŠ å›º (Security Hardening)
â”œâ”€â”€ ğŸ¼ ç¼–æ’å±‚ (Orchestration Layer)
â”‚   â”œâ”€â”€ Docker Composeç¼–æ’ (Compose Orchestration)
â”‚   â”œâ”€â”€ Kuberneteséƒ¨ç½² (K8s Deployment)
â”‚   â”œâ”€â”€ æœåŠ¡å‘ç° (Service Discovery)
â”‚   â””â”€â”€ è´Ÿè½½å‡è¡¡ (Load Balancing)
â”œâ”€â”€ ğŸ“Š ç›‘æ§è¿ç»´å±‚ (Monitoring & Operations Layer)
â”‚   â”œâ”€â”€ å®¹å™¨ç›‘æ§ (Container Monitoring)
â”‚   â”œâ”€â”€ æ—¥å¿—èšåˆ (Log Aggregation)
â”‚   â”œâ”€â”€ æ€§èƒ½ç›‘æ§ (Performance Monitoring)
â”‚   â””â”€â”€ è‡ªåŠ¨åŒ–è¿ç»´ (Automated Operations)
â””â”€â”€ â˜ï¸ äº‘æœåŠ¡å±‚ (Cloud Services Layer)
    â”œâ”€â”€ äº‘æä¾›å•†é›†æˆ (Cloud Provider Integration)
    â”œâ”€â”€ å¼¹æ€§ä¼¸ç¼© (Auto Scaling)
    â”œâ”€â”€ å¤‡ä»½æ¢å¤ (Backup & Recovery)
    â””â”€â”€ ç¾éš¾æ¢å¤ (Disaster Recovery)
```

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. å®¹å™¨åŒ–æ¶æ„

#### 1.1 Dockeré•œåƒè®¾è®¡

**å¤šé˜¶æ®µæ„å»ºç­–ç•¥**:

```dockerfile
# Dockerfile - å¤šé˜¶æ®µæ„å»º
# =========================

# æ„å»ºé˜¶æ®µ - ä½¿ç”¨Node.jsæ„å»ºåº”ç”¨
FROM node:18-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶packageæ–‡ä»¶
COPY package*.json ./

# å®‰è£…ä¾èµ– (åŒ…æ‹¬devDependenciesç”¨äºæ„å»º)
RUN npm ci --only=production=false

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN npm run build

# è¿è¡Œé˜¶æ®µ - ä½¿ç”¨è½»é‡çº§Node.jsè¿è¡Œæ—¶
FROM node:18-alpine AS runtime

# å®‰è£…å¿…è¦çš„ç³»ç»Ÿä¾èµ–
RUN apk add --no-cache \
    dumb-init \
    curl \
    && rm -rf /var/cache/apk/*

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nextjs:nodejs /app/package*.json ./

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER nextjs

# æš´éœ²ç«¯å£
EXPOSE 8080

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV NODE_ENV=production
ENV PORT=8080

# ä½¿ç”¨dumb-initå¯åŠ¨åº”ç”¨
ENTRYPOINT ["dumb-init", "--"]
CMD ["npm", "start"]
```

**é•œåƒä¼˜åŒ–ç­–ç•¥**:

```dockerfile
# Dockerfile.optimized - è¿›ä¸€æ­¥ä¼˜åŒ–ç‰ˆæœ¬
FROM node:18-alpine AS base

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apk add --no-cache \
    dumb-init \
    curl \
    tzdata \
    && rm -rf /var/cache/apk/*

# è®¾ç½®æ—¶åŒº
ENV TZ=Asia/Shanghai

FROM base AS deps
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .
RUN npm run build && npm prune --production

FROM base AS runtime
WORKDIR /app

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN addgroup -g 1001 appgroup && \
    adduser -u 1001 -S appuser -G appgroup

# å¤åˆ¶åº”ç”¨æ–‡ä»¶
COPY --from=builder --chown=appuser:appgroup /app/dist ./dist
COPY --from=builder --chown=appuser:appgroup /app/node_modules ./node_modules
COPY --from=builder --chown=appuser:appgroup /app/package.json ./

# è®¾ç½®æ­£ç¡®çš„æƒé™
RUN chown -R appuser:appgroup /app
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

EXPOSE 8080

ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/index.js"]
```

#### 1.2 é•œåƒå®‰å…¨åŠ å›º

**å®‰å…¨æœ€ä½³å®è·µ**:

```dockerfile
# Dockerfile.security - å®‰å…¨åŠ å›ºç‰ˆæœ¬
FROM node:18-alpine AS base

# æ›´æ–°åŒ…ç®¡ç†å™¨å¹¶å®‰è£…å®‰å…¨è¡¥ä¸
RUN apk update && apk upgrade && \
    apk add --no-cache \
    dumb-init \
    curl \
    ca-certificates \
    && rm -rf /var/cache/apk/* /tmp/*

# åˆ›å»ºä¸“ç”¨ç”¨æˆ·å’Œç»„
RUN addgroup -g 10001 appgroup && \
    adduser -u 10001 -S appuser -G appgroup -h /home/appuser

# è®¾ç½®å·¥ä½œç›®å½•æƒé™
WORKDIR /app
RUN chown -R appuser:appgroup /app

# å¤åˆ¶åº”ç”¨æ–‡ä»¶ (åœ¨åˆ‡æ¢ç”¨æˆ·ä¹‹å‰)
COPY --chown=appuser:appgroup package*.json ./
COPY --chown=appuser:appgroup dist ./dist

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN npm ci --only=production --no-audit --no-fund && \
    npm cache clean --force

# ç§»é™¤ä¸å¿…è¦çš„æ–‡ä»¶å’Œæƒé™
RUN rm -rf /usr/local/lib/node_modules/npm && \
    chmod -R 755 /app && \
    chmod 644 /app/package.json

# åˆ‡æ¢åˆ°éç‰¹æƒç”¨æˆ·
USER appuser

# è®¾ç½®å®‰å…¨ç¯å¢ƒå˜é‡
ENV NODE_ENV=production
ENV NODE_OPTIONS="--max-old-space-size=512 --max-http-header-size=16384"

# åªæš´éœ²å¿…è¦ç«¯å£
EXPOSE 8080

# è®¾ç½®èµ„æºé™åˆ¶
LABEL maintainer="Sira Team <team@sira.ai>"
LABEL version="1.0.0"
LABEL description="Sira AI Gateway - Secure Container Image"

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl -f -H "User-Agent: HealthCheck" http://localhost:8080/health || exit 1

# ä½¿ç”¨execæ ¼å¼çš„CMD
CMD ["dumb-init", "node", "dist/index.js"]
```

### 2. ç¼–æ’éƒ¨ç½²æ¶æ„

#### 2.1 Docker Composeç¼–æ’

**å®Œæ•´ç¯å¢ƒç¼–æ’**:

```yaml
# docker-compose.yml - å®Œæ•´å¼€å‘ç¯å¢ƒ
version: '3.8'

services:
  # ä¸»åº”ç”¨æœåŠ¡
  app:
    build:
      context: ..
      dockerfile: Dockerfile
      target: runtime
    ports:
      - '8080:8080'
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://db:5432/sira
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
      - monitoring
    networks:
      - sira-network
    restart: unless-stopped
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8080/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # PostgreSQLæ•°æ®åº“
  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=sira
      - POSTGRES_USER=sira
      - POSTGRES_PASSWORD=${DB_PASSWORD:-changeme}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - '5432:5432'
    networks:
      - sira-network
    restart: unless-stopped
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U sira -d sira']
      interval: 30s
      timeout: 10s
      retries: 3

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-changeme}
    volumes:
      - redis_data:/data
    ports:
      - '6379:6379'
    networks:
      - sira-network
    restart: unless-stopped
    healthcheck:
      test: ['CMD', 'redis-cli', '--raw', 'incr', 'ping']
      interval: 30s
      timeout: 10s
      retries: 3

  # ç›‘æ§æ ˆ
  monitoring:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    ports:
      - '9090:9090'
    networks:
      - sira-network
    restart: unless-stopped

  # Grafanaå¯è§†åŒ–
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    ports:
      - '3000:3000'
    depends_on:
      - monitoring
    networks:
      - sira-network
    restart: unless-stopped

  # æ—¥å¿—èšåˆ
  loki:
    image: grafana/loki:latest
    volumes:
      - ./monitoring/loki/config.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - '3100:3100'
    networks:
      - sira-network
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
  loki_data:

networks:
  sira-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

#### 2.2 Kuberneteséƒ¨ç½²

**K8såŸç”Ÿéƒ¨ç½²**:

```yaml
# k8s/deployment.yml - Kuberneteséƒ¨ç½²é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sira-gateway
  labels:
    app: sira-gateway
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sira-gateway
  template:
    metadata:
      labels:
        app: sira-gateway
    spec:
      containers:
        - name: sira-gateway
          image: sira/gateway:latest
          ports:
            - containerPort: 8080
              name: http
          env:
            - name: NODE_ENV
              value: 'production'
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: sira-secrets
                  key: database-url
            - name: REDIS_URL
              valueFrom:
                secretKeyRef:
                  name: sira-secrets
                  key: redis-url
          resources:
            requests:
              memory: '256Mi'
              cpu: '250m'
            limits:
              memory: '512Mi'
              cpu: '500m'
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 10001
            capabilities:
              drop:
                - ALL
      securityContext:
        fsGroup: 10001
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - sira-gateway
                topologyKey: kubernetes.io/hostname

---
apiVersion: v1
kind: Service
metadata:
  name: sira-gateway-service
spec:
  selector:
    app: sira-gateway
  ports:
    - port: 80
      targetPort: 8080
      protocol: TCP
  type: LoadBalancer

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: sira-gateway-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: 'letsencrypt-prod'
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - api.sira.ai
      secretName: sira-tls
  rules:
    - host: api.sira.ai
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: sira-gateway-service
                port:
                  number: 80
```

#### 2.3 æœåŠ¡ç½‘æ ¼é›†æˆ

**IstioæœåŠ¡ç½‘æ ¼é…ç½®**:

```yaml
# istio/gateway.yml - Istio Gatewayé…ç½®
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: sira-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 80
        name: http
        protocol: HTTP
      hosts:
        - api.sira.ai
    - port:
        number: 443
        name: https
        protocol: HTTPS
      tls:
        mode: SIMPLE
        credentialName: sira-tls
      hosts:
        - api.sira.ai

---
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: sira-gateway
spec:
  hosts:
    - api.sira.ai
  gateways:
    - sira-gateway
  http:
    - match:
        - uri:
            prefix: '/api/v1'
      route:
        - destination:
            host: sira-gateway
            port:
              number: 8080
      timeout: 30s
      retries:
        attempts: 3
        perTryTimeout: 10s
    - match:
        - uri:
            prefix: '/health'
      route:
        - destination:
            host: sira-gateway
            port:
              number: 8080

---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: sira-gateway-auth
  namespace: default
spec:
  selector:
    matchLabels:
      app: sira-gateway
  action: ALLOW
  rules:
    - from:
        - source:
            requestPrincipals: ['*']
      to:
        - operation:
            methods: ['GET', 'POST']
            paths: ['/api/v1/*', '/health']
```

---

## ğŸ¯ åŠŸèƒ½èŒè´£è¯¦è§£

### 1. å®¹å™¨åŒ–éƒ¨ç½²

#### 1.1 é•œåƒæ„å»ºä¸ä¼˜åŒ–

**è‡ªåŠ¨åŒ–é•œåƒæ„å»ºæµç¨‹**:

```javascript
class DockerImageBuilder {
  constructor(options = {}) {
    this.docker = new Docker();
    this.registry = options.registry || 'docker.io';
    this.namespace = options.namespace || 'sira';
    this.buildArgs = options.buildArgs || {};
  }

  // æ„å»ºå¤šæ¶æ„é•œåƒ
  async buildMultiArch(imageName, context, dockerfile = 'Dockerfile') {
    const platforms = ['linux/amd64', 'linux/arm64'];
    const tags = await this.generateTags(imageName);

    console.log(`Building multi-arch image: ${imageName}`);

    // æ„å»ºæ¯ä¸ªæ¶æ„çš„é•œåƒ
    const builds = platforms.map(async platform => {
      const platformTag = `${imageName}-${platform.replace('/', '-')}`;

      await this.docker.buildImage({
        context,
        dockerfile,
        t: platformTag,
        buildargs: {
          ...this.buildArgs,
          TARGETPLATFORM: platform,
        },
        platform,
      });

      return platformTag;
    });

    await Promise.all(builds);

    // åˆ›å»ºmanifestå¹¶æ¨é€å¤šæ¶æ„é•œåƒ
    await this.createAndPushManifest(imageName, platforms, tags);

    console.log(`âœ… Multi-arch image built and pushed: ${imageName}`);
  }

  // é•œåƒå®‰å…¨æ‰«æ
  async scanImage(imageName) {
    console.log(`Scanning image for vulnerabilities: ${imageName}`);

    try {
      const scanResult = await this.runTrivyScan(imageName);

      if (scanResult.vulnerabilities.high > 0) {
        throw new Error(
          `High-severity vulnerabilities found: ${scanResult.vulnerabilities.high}`
        );
      }

      console.log('âœ… Image security scan passed');
      return scanResult;
    } catch (error) {
      console.error('âŒ Image security scan failed:', error.message);
      throw error;
    }
  }

  // é•œåƒå¤§å°ä¼˜åŒ–
  async optimizeImage(imageName) {
    console.log(`Optimizing image size: ${imageName}`);

    // åˆ†æé•œåƒå±‚
    const layers = await this.analyzeImageLayers(imageName);

    // è¯†åˆ«ä¼˜åŒ–æœºä¼š
    const optimizations = this.identifyOptimizations(layers);

    // åº”ç”¨ä¼˜åŒ–
    const optimizedImage = await this.applyOptimizations(
      imageName,
      optimizations
    );

    // éªŒè¯ä¼˜åŒ–æ•ˆæœ
    const originalSize = await this.getImageSize(imageName);
    const optimizedSize = await this.getImageSize(optimizedImage);
    const reduction = ((originalSize - optimizedSize) / originalSize) * 100;

    console.log(`âœ… Image optimized: ${reduction.toFixed(1)}% size reduction`);
    console.log(`   Original: ${this.formatBytes(originalSize)}`);
    console.log(`   Optimized: ${this.formatBytes(optimizedSize)}`);

    return optimizedImage;
  }

  // ç”Ÿæˆé•œåƒæ ‡ç­¾
  async generateTags(imageName) {
    const tags = [imageName];

    // æ·»åŠ ç‰ˆæœ¬æ ‡ç­¾
    const version = await this.getPackageVersion();
    tags.push(`${imageName}:${version}`);

    // æ·»åŠ latestæ ‡ç­¾ (ä»…ä¸»åˆ†æ”¯)
    if (await this.isMainBranch()) {
      tags.push(`${imageName}:latest`);
    }

    // æ·»åŠ Gitæ ‡ç­¾
    const gitTag = await this.getGitTag();
    if (gitTag) {
      tags.push(`${imageName}:${gitTag}`);
    }

    // æ·»åŠ æ—¶é—´æˆ³æ ‡ç­¾
    const timestamp = new Date().toISOString().split('T')[0];
    tags.push(`${imageName}:${timestamp}`);

    return tags;
  }
}
```

#### 1.2 é•œåƒåˆ†å‘ä¸ç®¡ç†

**é•œåƒä»“åº“ç®¡ç†**:

```javascript
class ImageRegistryManager {
  constructor(config = {}) {
    this.registries = new Map();
    this.defaultRegistry = config.defaultRegistry || 'docker.io';

    // æ”¯æŒå¤šä¸ªé•œåƒä»“åº“
    this.addRegistry('dockerhub', {
      url: 'https://index.docker.io/v1/',
      auth: config.dockerhubAuth,
    });

    this.addRegistry('ecr', {
      url: config.ecrUrl,
      auth: config.ecrAuth,
      type: 'aws',
    });

    this.addRegistry('gcr', {
      url: config.gcrUrl,
      auth: config.gcrAuth,
      type: 'gcp',
    });
  }

  // æ¨é€é•œåƒåˆ°å¤šä¸ªä»“åº“
  async pushToRegistries(imageName, tags, registries = null) {
    const targetRegistries = registries || Array.from(this.registries.keys());

    for (const registryName of targetRegistries) {
      const registry = this.registries.get(registryName);
      if (!registry) continue;

      console.log(`Pushing to registry: ${registryName}`);

      for (const tag of tags) {
        const fullImageName = `${registry.url}/${imageName}:${tag}`;

        try {
          await this.authenticateRegistry(registry);
          await this.docker.push(fullImageName);
          console.log(`âœ… Pushed: ${fullImageName}`);
        } catch (error) {
          console.error(`âŒ Failed to push to ${registryName}:`, error.message);
        }
      }
    }
  }

  // é•œåƒæ¸…ç†ç­–ç•¥
  async cleanupOldImages(imageName, keepVersions = 10) {
    console.log(`Cleaning up old images for: ${imageName}`);

    // è·å–æ‰€æœ‰æ ‡ç­¾
    const allTags = await this.listImageTags(imageName);

    // æŒ‰ç‰ˆæœ¬æ’åº
    const sortedTags = this.sortTagsByVersion(allTags);

    // ä¿ç•™æœ€æ–°ç‰ˆæœ¬
    const tagsToDelete = sortedTags.slice(keepVersions);

    // åˆ é™¤æ—§ç‰ˆæœ¬
    for (const tag of tagsToDelete) {
      try {
        await this.deleteImageTag(imageName, tag);
        console.log(`ğŸ—‘ï¸ Deleted old image: ${imageName}:${tag}`);
      } catch (error) {
        console.warn(`Failed to delete ${tag}:`, error.message);
      }
    }

    console.log(
      `âœ… Cleanup completed. Kept ${keepVersions} versions, deleted ${tagsToDelete.length} old versions`
    );
  }

  // é•œåƒæ¼æ´ç›‘æ§
  async monitorVulnerabilities(imageName) {
    const vulnerabilities = await this.scanImageVulnerabilities(imageName);

    // æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
    const critical = vulnerabilities.filter(v => v.severity === 'CRITICAL');
    const high = vulnerabilities.filter(v => v.severity === 'HIGH');

    if (critical.length > 0 || high.length > 0) {
      console.warn(`ğŸš¨ Security vulnerabilities found in ${imageName}:`);
      console.warn(`   Critical: ${critical.length}`);
      console.warn(`   High: ${high.length}`);

      // å‘é€å‘Šè­¦
      await this.sendSecurityAlert(imageName, vulnerabilities);
    }

    return {
      total: vulnerabilities.length,
      critical: critical.length,
      high: high.length,
      medium: vulnerabilities.filter(v => v.severity === 'MEDIUM').length,
      low: vulnerabilities.filter(v => v.severity === 'LOW').length,
    };
  }
}
```

### 2. ç¼–æ’ä¸æ‰©å±•

#### 2.1 å¼¹æ€§ä¼¸ç¼©

**è‡ªåŠ¨æ‰©ç¼©å®¹ç­–ç•¥**:

```javascript
class AutoScaler {
  constructor(k8sClient, options = {}) {
    this.k8s = k8sClient;
    this.options = {
      minReplicas: options.minReplicas || 1,
      maxReplicas: options.maxReplicas || 10,
      targetCPUUtilizationPercentage: options.targetCPU || 70,
      targetMemoryUtilizationPercentage: options.targetMemory || 80,
      scaleUpThreshold: options.scaleUpThreshold || 80,
      scaleDownThreshold: options.scaleDownThreshold || 50,
      stabilizationWindowSeconds: options.stabilizationWindow || 300,
      ...options,
    };

    this.metricsHistory = new Map();
  }

  // ç›‘æ§å’Œæ‰©ç¼©å®¹
  async monitorAndScale(deploymentName, namespace = 'default') {
    const metrics = await this.getCurrentMetrics(deploymentName, namespace);
    this.updateMetricsHistory(deploymentName, metrics);

    const currentReplicas = await this.getCurrentReplicas(
      deploymentName,
      namespace
    );
    const recommendedReplicas = this.calculateRecommendedReplicas(
      metrics,
      currentReplicas
    );

    if (recommendedReplicas !== currentReplicas) {
      await this.scaleDeployment(
        deploymentName,
        namespace,
        recommendedReplicas
      );

      console.log(
        `ğŸ”„ Scaled ${deploymentName} from ${currentReplicas} to ${recommendedReplicas} replicas`
      );
      console.log(
        `   CPU: ${metrics.cpu}%, Memory: ${metrics.memory}%, Requests: ${metrics.requestsPerSecond} RPS`
      );
    }

    return recommendedReplicas;
  }

  // è®¡ç®—æ¨èå‰¯æœ¬æ•°
  calculateRecommendedReplicas(metrics, currentReplicas) {
    const cpuScale = metrics.cpu / this.options.targetCPUUtilizationPercentage;
    const memoryScale =
      metrics.memory / this.options.targetMemoryUtilizationPercentage;
    const requestScale = metrics.requestsPerSecond / 100; // å‡è®¾100 RPSéœ€è¦1ä¸ªå‰¯æœ¬

    // å–æœ€å¤§å€¼ä½œä¸ºæ‰©ç¼©å®¹å› å­
    const scaleFactor = Math.max(cpuScale, memoryScale, requestScale);

    let recommendedReplicas = Math.ceil(currentReplicas * scaleFactor);

    // åº”ç”¨çº¦æŸ
    recommendedReplicas = Math.max(
      this.options.minReplicas,
      recommendedReplicas
    );
    recommendedReplicas = Math.min(
      this.options.maxReplicas,
      recommendedReplicas
    );

    // æ£€æŸ¥ç¨³å®šçª—å£
    if (!this.isStabilizationPeriodPassed(recommendedReplicas)) {
      return currentReplicas; // ä¸è¿›è¡Œæ‰©ç¼©å®¹
    }

    return recommendedReplicas;
  }

  // æ‰§è¡Œæ‰©ç¼©å®¹
  async scaleDeployment(deploymentName, namespace, replicas) {
    const appsApi = this.k8s.api.apps.v1;

    const deployment = await appsApi
      .namespaces(namespace)
      .deployments(deploymentName)
      .get();

    deployment.spec.replicas = replicas;

    await appsApi.namespaces(namespace).deployments(deploymentName).patch({
      spec: {
        replicas,
      },
    });

    // è®°å½•æ‰©ç¼©å®¹äº‹ä»¶
    await this.recordScalingEvent(deploymentName, namespace, replicas);
  }

  // é¢„æµ‹æ€§æ‰©ç¼©å®¹
  async predictiveScaling(deploymentName, namespace) {
    const historicalData = await this.getHistoricalMetrics(
      deploymentName,
      namespace
    );
    const prediction = await this.predictFutureLoad(historicalData);

    if (prediction.confidence > 0.8) {
      const predictedReplicas = this.calculateRecommendedReplicas(
        prediction.metrics,
        await this.getCurrentReplicas(deploymentName, namespace)
      );

      if (
        Math.abs(
          predictedReplicas -
            (await this.getCurrentReplicas(deploymentName, namespace))
        ) > 1
      ) {
        console.log(
          `ğŸ”® Predictive scaling: ${predictedReplicas} replicas (confidence: ${(prediction.confidence * 100).toFixed(1)}%)`
        );
        await this.scaleDeployment(
          deploymentName,
          namespace,
          predictedReplicas
        );
      }
    }
  }

  // è·å–å½“å‰æŒ‡æ ‡
  async getCurrentMetrics(deploymentName, namespace) {
    const metricsApi = this.k8s.api.metrics.k8s.io.v1beta1;

    try {
      const pods = await this.k8s.api.v1.namespaces(namespace).pods.get({
        qs: {
          labelSelector: `app=${deploymentName}`,
        },
      });

      let totalCPU = 0;
      let totalMemory = 0;
      let podCount = 0;

      for (const pod of pods.items) {
        const podMetrics = await metricsApi
          .namespaces(namespace)
          .pods(pod.metadata.name)
          .get();

        if (podMetrics.containers && podMetrics.containers.length > 0) {
          const container = podMetrics.containers[0];
          totalCPU += parseInt(container.usage.cpu.replace('n', '')) / 1000000; // è½¬æ¢ä¸ºmillicores
          totalMemory +=
            parseInt(container.usage.memory.replace('Ki', '')) / 1024; // è½¬æ¢ä¸ºMi
          podCount++;
        }
      }

      return {
        cpu: podCount > 0 ? ((totalCPU / podCount) * 100) / 1000 : 0, // è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        memory: podCount > 0 ? totalMemory / podCount : 0,
        podCount,
        timestamp: new Date(),
      };
    } catch (error) {
      console.error('Failed to get metrics:', error);
      return { cpu: 0, memory: 0, podCount: 0 };
    }
  }
}
```

#### 2.2 æœåŠ¡å‘ç°ä¸è´Ÿè½½å‡è¡¡

**æ™ºèƒ½æœåŠ¡å‘ç°**:

```javascript
class ServiceDiscovery {
  constructor(options = {}) {
    this.providers = new Map();
    this.cache = new Map();
    this.ttl = options.ttl || 30000; // 30ç§’ç¼“å­˜

    // æ³¨å†ŒæœåŠ¡å‘ç°æä¾›è€…
    this.registerProvider('kubernetes', new KubernetesServiceDiscovery());
    this.registerProvider('consul', new ConsulServiceDiscovery());
    this.registerProvider('etcd', new EtcdServiceDiscovery());
  }

  // æœåŠ¡æ³¨å†Œ
  async registerService(serviceName, serviceInfo) {
    const provider = this.getProvider();

    await provider.register(serviceName, {
      id: serviceInfo.id || `${serviceName}-${Date.now()}`,
      name: serviceName,
      address: serviceInfo.address,
      port: serviceInfo.port,
      tags: serviceInfo.tags || [],
      meta: serviceInfo.meta || {},
      check: serviceInfo.check || this.createDefaultCheck(serviceInfo),
    });

    console.log(
      `âœ… Service registered: ${serviceName} at ${serviceInfo.address}:${serviceInfo.port}`
    );
  }

  // æœåŠ¡å‘ç°
  async discoverServices(serviceName, options = {}) {
    const cacheKey = `${serviceName}:${JSON.stringify(options)}`;

    // æ£€æŸ¥ç¼“å­˜
    const cached = this.cache.get(cacheKey);
    if (cached && Date.now() - cached.timestamp < this.ttl) {
      return cached.services;
    }

    const provider = this.getProvider();
    const services = await provider.discover(serviceName, options);

    // åº”ç”¨è´Ÿè½½å‡è¡¡ç­–ç•¥
    const balancedServices = this.applyLoadBalancing(
      services,
      options.strategy || 'round-robin'
    );

    // æ›´æ–°ç¼“å­˜
    this.cache.set(cacheKey, {
      services: balancedServices,
      timestamp: Date.now(),
    });

    return balancedServices;
  }

  // å¥åº·æ£€æŸ¥
  async healthCheck(serviceId) {
    const provider = this.getProvider();
    return await provider.healthCheck(serviceId);
  }

  // æœåŠ¡æ³¨é”€
  async deregisterService(serviceId) {
    const provider = this.getProvider();
    await provider.deregister(serviceId);
    console.log(`âœ… Service deregistered: ${serviceId}`);
  }

  // è´Ÿè½½å‡è¡¡ç­–ç•¥
  applyLoadBalancing(services, strategy) {
    const healthyServices = services.filter(s => s.status === 'passing');

    switch (strategy) {
      case 'round-robin':
        return this.roundRobinBalance(healthyServices);
      case 'least-connections':
        return this.leastConnectionsBalance(healthyServices);
      case 'weighted':
        return this.weightedBalance(healthyServices);
      case 'random':
        return this.randomBalance(healthyServices);
      default:
        return healthyServices;
    }
  }

  roundRobinBalance(services) {
    // ç®€å•çš„è½®è¯¢ç­–ç•¥
    const sorted = services.sort(
      (a, b) => (a.roundRobinIndex || 0) - (b.roundRobinIndex || 0)
    );
    const selected = sorted[0];

    // æ›´æ–°è½®è¯¢ç´¢å¼•
    services.forEach(s => {
      s.roundRobinIndex = (s.roundRobinIndex || 0) + 1;
    });

    return [selected];
  }

  leastConnectionsBalance(services) {
    return services.sort(
      (a, b) => (a.activeConnections || 0) - (b.activeConnections || 0)
    );
  }

  weightedBalance(services) {
    const totalWeight = services.reduce((sum, s) => sum + (s.weight || 1), 0);
    let random = Math.random() * totalWeight;

    for (const service of services) {
      random -= service.weight || 1;
      if (random <= 0) {
        return [service];
      }
    }

    return [services[0]];
  }

  randomBalance(services) {
    const randomIndex = Math.floor(Math.random() * services.length);
    return [services[randomIndex]];
  }
}
```

---

## ğŸ› ï¸ æŠ€æœ¯å®ç°è¯¦è§£

### 1. åŸºç¡€è®¾æ–½å³ä»£ç 

#### 1.1 éƒ¨ç½²é…ç½®ç®¡ç†

**åŸºç¡€è®¾æ–½å³ä»£ç å®ç°**:

```javascript
class InfrastructureAsCode {
  constructor() {
    this.templates = new Map();
    this.environments = new Map();
    this.variables = new Map();
  }

  // å®šä¹‰ç¯å¢ƒ
  defineEnvironment(name, config) {
    this.environments.set(name, {
      name,
      config,
      templates: [],
      variables: new Map(),
      hooks: {
        preDeploy: [],
        postDeploy: [],
        preDestroy: [],
        postDestroy: [],
      },
    });
  }

  // æ³¨å†ŒåŸºç¡€è®¾æ–½æ¨¡æ¿
  registerTemplate(name, template) {
    this.templates.set(name, {
      name,
      content: template,
      variables: this.extractVariables(template),
      metadata: {
        description: template.description,
        version: template.version,
        author: template.author,
      },
    });
  }

  // ç”Ÿæˆéƒ¨ç½²é…ç½®
  async generateDeployment(environmentName, options = {}) {
    const environment = this.environments.get(environmentName);
    if (!environment) {
      throw new Error(`Environment '${environmentName}' not found`);
    }

    const deployment = {
      environment: environmentName,
      timestamp: new Date().toISOString(),
      resources: [],
      variables: {},
      metadata: {},
    };

    // åˆå¹¶å˜é‡
    const allVariables = this.mergeVariables(
      environment,
      options.variables || {}
    );
    deployment.variables = allVariables;

    // ç”Ÿæˆæ¯ä¸ªæ¨¡æ¿çš„èµ„æº
    for (const templateName of environment.templates) {
      const template = this.templates.get(templateName);
      if (!template) continue;

      const resource = await this.renderTemplate(template, allVariables);
      deployment.resources.push(resource);
    }

    // åº”ç”¨éƒ¨ç½²ç­–ç•¥
    deployment.strategy = this.determineDeploymentStrategy(
      environment,
      options
    );

    return deployment;
  }

  // éƒ¨ç½²æ‰§è¡Œ
  async deploy(deploymentConfig, options = {}) {
    console.log(`ğŸš€ Starting deployment to ${deploymentConfig.environment}`);

    try {
      // é¢„éƒ¨ç½²é’©å­
      await this.executeHooks(deploymentConfig.environment, 'preDeploy');

      // éªŒè¯éƒ¨ç½²é…ç½®
      await this.validateDeployment(deploymentConfig);

      // åˆ›å»ºéƒ¨ç½²è®¡åˆ’
      const plan = await this.createDeploymentPlan(deploymentConfig);

      // æ‰§è¡Œéƒ¨ç½²
      const result = await this.executeDeployment(plan, options);

      // åéƒ¨ç½²é’©å­
      await this.executeHooks(deploymentConfig.environment, 'postDeploy');

      console.log(`âœ… Deployment completed successfully`);
      return result;
    } catch (error) {
      console.error(`âŒ Deployment failed:`, error.message);

      // å›æ»šå¤„ç†
      if (options.rollbackOnFailure) {
        await this.rollback(deploymentConfig);
      }

      throw error;
    }
  }

  // éƒ¨ç½²éªŒè¯
  async validateDeployment(deployment) {
    const issues = [];

    // éªŒè¯å¿…éœ€å˜é‡
    for (const [key, value] of Object.entries(deployment.variables)) {
      if (value === undefined || value === null || value === '') {
        issues.push(`Missing required variable: ${key}`);
      }
    }

    // éªŒè¯èµ„æºé…ç½®
    for (const resource of deployment.resources) {
      const resourceIssues = await this.validateResource(resource);
      issues.push(...resourceIssues);
    }

    // éªŒè¯ä¾èµ–å…³ç³»
    const dependencyIssues = this.validateDependencies(deployment.resources);
    issues.push(...dependencyIssues);

    if (issues.length > 0) {
      throw new ValidationError('Deployment validation failed', issues);
    }

    return true;
  }

  // åˆ›å»ºéƒ¨ç½²è®¡åˆ’
  async createDeploymentPlan(deployment) {
    const plan = {
      phases: [],
      resources: deployment.resources,
      rollbackPlan: [],
      estimatedDuration: 0,
    };

    // åˆ†æä¾èµ–å…³ç³»
    const dependencyGraph = this.buildDependencyGraph(deployment.resources);

    // åˆ†é˜¶æ®µæ‰§è¡Œ
    const phases = this.groupByPhases(dependencyGraph);

    for (const phase of phases) {
      plan.phases.push({
        name: phase.name,
        resources: phase.resources,
        parallel: phase.parallel,
        timeout: phase.timeout || 300000, // 5åˆ†é’Ÿ
      });

      plan.estimatedDuration += phase.estimatedDuration || 60000; // 1åˆ†é’Ÿ
    }

    // ç”Ÿæˆå›æ»šè®¡åˆ’
    plan.rollbackPlan = this.generateRollbackPlan(phases);

    return plan;
  }

  // æ‰§è¡Œéƒ¨ç½²
  async executeDeployment(plan, options) {
    const results = {
      phases: [],
      totalDuration: 0,
      success: true,
      errors: [],
    };

    const startTime = Date.now();

    for (const phase of plan.phases) {
      console.log(`ğŸ“¦ Executing phase: ${phase.name}`);

      const phaseStart = Date.now();

      try {
        const phaseResult = await this.executePhase(phase, options);
        results.phases.push(phaseResult);

        const phaseDuration = Date.now() - phaseStart;
        console.log(`âœ… Phase '${phase.name}' completed in ${phaseDuration}ms`);
      } catch (error) {
        console.error(`âŒ Phase '${phase.name}' failed:`, error.message);
        results.errors.push({
          phase: phase.name,
          error: error.message,
          timestamp: new Date(),
        });

        results.success = false;

        // åœæ­¢æ‰§è¡Œåç»­é˜¶æ®µ
        break;
      }
    }

    results.totalDuration = Date.now() - startTime;

    // è®°å½•éƒ¨ç½²ç»“æœ
    await this.recordDeploymentResult(results);

    return results;
  }

  // æ‰§è¡Œéƒ¨ç½²é˜¶æ®µ
  async executePhase(phase, options) {
    const result = {
      name: phase.name,
      resources: [],
      duration: 0,
      success: true,
    };

    const startTime = Date.now();

    if (phase.parallel) {
      // å¹¶è¡Œæ‰§è¡Œ
      const promises = phase.resources.map(resource =>
        this.deployResource(resource, options)
      );

      const resourceResults = await Promise.allSettled(promises);

      for (let i = 0; i < resourceResults.length; i++) {
        const resourceResult = resourceResults[i];
        const resource = phase.resources[i];

        result.resources.push({
          name: resource.name,
          type: resource.type,
          success: resourceResult.status === 'fulfilled',
          error:
            resourceResult.status === 'rejected'
              ? resourceResult.reason.message
              : null,
          duration:
            resourceResult.status === 'fulfilled'
              ? resourceResult.value.duration
              : 0,
        });
      }

      result.success = result.resources.every(r => r.success);
    } else {
      // ä¸²è¡Œæ‰§è¡Œ
      for (const resource of phase.resources) {
        try {
          const resourceResult = await this.deployResource(resource, options);
          result.resources.push({
            name: resource.name,
            type: resource.type,
            success: true,
            duration: resourceResult.duration,
          });
        } catch (error) {
          result.resources.push({
            name: resource.name,
            type: resource.type,
            success: false,
            error: error.message,
          });

          result.success = false;
          break;
        }
      }
    }

    result.duration = Date.now() - startTime;
    return result;
  }

  // éƒ¨ç½²å•ä¸ªèµ„æº
  async deployResource(resource, options) {
    const deployer = this.getResourceDeployer(resource.type);

    console.log(`  ğŸ“‹ Deploying ${resource.type}: ${resource.name}`);

    const startTime = Date.now();

    try {
      await deployer.deploy(resource, options);
      const duration = Date.now() - startTime;

      console.log(`    âœ… ${resource.name} deployed in ${duration}ms`);

      return { duration, success: true };
    } catch (error) {
      const duration = Date.now() - startTime;
      console.error(
        `    âŒ ${resource.name} deployment failed:`,
        error.message
      );

      throw error;
    }
  }
}
```

#### 1.2 é…ç½®æ¼‚ç§»æ£€æµ‹

**åŸºç¡€è®¾æ–½çŠ¶æ€ç®¡ç†**:

```javascript
class InfrastructureDriftDetection {
  constructor() {
    this.baselines = new Map();
    this.driftHistory = [];
    this.tolerance = {
      cpu: 0.05, // 5% CPUä½¿ç”¨ç‡å®¹å¿åº¦
      memory: 0.1, // 10% å†…å­˜ä½¿ç”¨ç‡å®¹å¿åº¦
      replicas: 0, // å‰¯æœ¬æ•°å¿…é¡»ç²¾ç¡®åŒ¹é…
      image: 'exact', // é•œåƒç‰ˆæœ¬å¿…é¡»å®Œå…¨åŒ¹é…
    };
  }

  // å»ºç«‹åŸºçº¿
  async establishBaseline(environment, resources) {
    const baseline = {
      environment,
      timestamp: new Date(),
      resources: {},
      checksum: null,
    };

    for (const resource of resources) {
      baseline.resources[resource.name] = {
        type: resource.type,
        spec: deepClone(resource.spec),
        status: await this.getCurrentState(resource),
      };
    }

    baseline.checksum = this.calculateChecksum(baseline.resources);
    this.baselines.set(environment, baseline);

    console.log(`ğŸ“‹ Baseline established for environment: ${environment}`);
    return baseline;
  }

  // æ£€æµ‹æ¼‚ç§»
  async detectDrift(environment) {
    const baseline = this.baselines.get(environment);
    if (!baseline) {
      throw new Error(`No baseline found for environment: ${environment}`);
    }

    const currentState = await this.getCurrentEnvironmentState(environment);
    const drift = this.compareStates(baseline.resources, currentState);

    if (drift.hasDrift) {
      console.warn(`âš ï¸  Infrastructure drift detected in ${environment}`);
      drift.changes.forEach(change => {
        console.warn(
          `  ${change.type}: ${change.resource} - ${change.description}`
        );
      });

      // è®°å½•æ¼‚ç§»å†å²
      this.driftHistory.push({
        environment,
        timestamp: new Date(),
        baselineChecksum: baseline.checksum,
        currentChecksum: this.calculateChecksum(currentState),
        drift,
      });

      // å‘é€å‘Šè­¦
      await this.sendDriftAlert(environment, drift);
    }

    return drift;
  }

  // æ¯”è¾ƒçŠ¶æ€
  compareStates(baseline, current) {
    const changes = [];
    let hasDrift = false;

    for (const [resourceName, baselineResource] of Object.entries(baseline)) {
      const currentResource = current[resourceName];

      if (!currentResource) {
        changes.push({
          type: 'missing',
          resource: resourceName,
          description: 'Resource no longer exists',
        });
        hasDrift = true;
        continue;
      }

      const resourceDrift = this.compareResource(
        baselineResource,
        currentResource
      );
      if (resourceDrift.hasDrift) {
        changes.push(...resourceDrift.changes);
        hasDrift = true;
      }
    }

    // æ£€æŸ¥æ–°å¢èµ„æº
    for (const resourceName of Object.keys(current)) {
      if (!baseline[resourceName]) {
        changes.push({
          type: 'added',
          resource: resourceName,
          description: 'New resource added',
        });
        hasDrift = true;
      }
    }

    return { hasDrift, changes };
  }

  // æ¯”è¾ƒå•ä¸ªèµ„æº
  compareResource(baseline, current) {
    const changes = [];
    let hasDrift = false;

    // æ¯”è¾ƒè§„æ ¼
    const specDrift = this.compareSpecs(baseline.spec, current.spec);
    if (specDrift.hasDrift) {
      changes.push(...specDrift.changes);
      hasDrift = true;
    }

    // æ¯”è¾ƒçŠ¶æ€ (æ ¹æ®å®¹å¿åº¦)
    const statusDrift = this.compareStatus(baseline.status, current.status);
    if (statusDrift.hasDrift) {
      changes.push(...statusDrift.changes);
      hasDrift = true;
    }

    return { hasDrift, changes };
  }

  // æ¯”è¾ƒè§„æ ¼ (å¿…é¡»å®Œå…¨åŒ¹é…)
  compareSpecs(baselineSpec, currentSpec) {
    const changes = [];
    let hasDrift = false;

    // é€’å½’æ¯”è¾ƒå¯¹è±¡
    const compare = (baseline, current, path = '') => {
      if (typeof baseline !== typeof current) {
        changes.push({
          type: 'type_mismatch',
          resource: path,
          description: `Type changed from ${typeof baseline} to ${typeof current}`,
        });
        hasDrift = true;
        return;
      }

      if (typeof baseline === 'object' && baseline !== null) {
        const baselineKeys = Object.keys(baseline).sort();
        const currentKeys = Object.keys(current).sort();

        if (!arraysEqual(baselineKeys, currentKeys)) {
          changes.push({
            type: 'keys_mismatch',
            resource: path,
            description: `Keys changed from [${baselineKeys.join(',')}] to [${currentKeys.join(',')}]`,
          });
          hasDrift = true;
          return;
        }

        for (const key of baselineKeys) {
          compare(baseline[key], current[key], path ? `${path}.${key}` : key);
        }
      } else if (baseline !== current) {
        changes.push({
          type: 'value_changed',
          resource: path,
          description: `Value changed from '${baseline}' to '${current}'`,
        });
        hasDrift = true;
      }
    };

    compare(baselineSpec, currentSpec);
    return { hasDrift, changes };
  }

  // æ¯”è¾ƒçŠ¶æ€ (è€ƒè™‘å®¹å¿åº¦)
  compareStatus(baselineStatus, currentStatus) {
    const changes = [];
    let hasDrift = false;

    // CPUä½¿ç”¨ç‡æ¯”è¾ƒ
    if (Math.abs(baselineStatus.cpu - currentStatus.cpu) > this.tolerance.cpu) {
      changes.push({
        type: 'cpu_drift',
        resource: 'cpu',
        description: `CPU usage changed from ${baselineStatus.cpu}% to ${currentStatus.cpu}%`,
      });
      hasDrift = true;
    }

    // å†…å­˜ä½¿ç”¨ç‡æ¯”è¾ƒ
    if (
      Math.abs(baselineStatus.memory - currentStatus.memory) >
      this.tolerance.memory
    ) {
      changes.push({
        type: 'memory_drift',
        resource: 'memory',
        description: `Memory usage changed from ${baselineStatus.memory}% to ${currentStatus.memory}%`,
      });
      hasDrift = true;
    }

    // å‰¯æœ¬æ•°æ¯”è¾ƒ
    if (baselineStatus.replicas !== currentStatus.replicas) {
      changes.push({
        type: 'replicas_drift',
        resource: 'replicas',
        description: `Replicas changed from ${baselineStatus.replicas} to ${currentStatus.replicas}`,
      });
      hasDrift = true;
    }

    // é•œåƒç‰ˆæœ¬æ¯”è¾ƒ
    if (
      this.tolerance.image === 'exact' &&
      baselineStatus.image !== currentStatus.image
    ) {
      changes.push({
        type: 'image_drift',
        resource: 'image',
        description: `Image changed from ${baselineStatus.image} to ${currentStatus.image}`,
      });
      hasDrift = true;
    }

    return { hasDrift, changes };
  }

  // è‡ªåŠ¨ä¿®å¤æ¼‚ç§»
  async autoRemediate(environment, drift) {
    console.log(`ğŸ”§ Starting auto-remediation for ${environment}`);

    const remediationPlan = this.generateRemediationPlan(drift);

    for (const step of remediationPlan) {
      try {
        console.log(`  ğŸ“‹ Executing: ${step.description}`);
        await step.execute();
        console.log(`  âœ… Completed: ${step.description}`);
      } catch (error) {
        console.error(`  âŒ Failed: ${step.description} - ${error.message}`);

        if (!step.continueOnFailure) {
          throw error;
        }
      }
    }

    console.log(`âœ… Auto-remediation completed for ${environment}`);
  }

  // ç”Ÿæˆä¿®å¤è®¡åˆ’
  generateRemediationPlan(drift) {
    const plan = [];

    for (const change of drift.changes) {
      switch (change.type) {
        case 'cpu_drift':
        case 'memory_drift':
          plan.push({
            description: `Adjusting autoscaling for ${change.resource}`,
            execute: () =>
              this.adjustAutoscaling(change.resource, drift.baseline),
            continueOnFailure: true,
          });
          break;

        case 'replicas_drift':
          plan.push({
            description: `Scaling ${change.resource} back to ${drift.baseline.replicas} replicas`,
            execute: () =>
              this.scaleToBaseline(change.resource, drift.baseline),
            continueOnFailure: false,
          });
          break;

        case 'image_drift':
          plan.push({
            description: `Rolling back ${change.resource} to image ${drift.baseline.image}`,
            execute: () => this.rollbackImage(change.resource, drift.baseline),
            continueOnFailure: false,
          });
          break;

        case 'missing':
          plan.push({
            description: `Recreating missing resource ${change.resource}`,
            execute: () =>
              this.recreateResource(change.resource, drift.baseline),
            continueOnFailure: false,
          });
          break;
      }
    }

    return plan;
  }
}
```

---

## ğŸ“ˆ å‘å±•è§„åˆ’

### 1. çŸ­æœŸè§„åˆ’ (0-6ä¸ªæœˆ)

#### 1.1 å®¹å™¨åŒ–å®Œå–„

- [ ] **é•œåƒä¼˜åŒ–**
  - [ ] å®ç°å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–
  - [ ] æ·»åŠ é•œåƒå¤§å°åˆ†æå·¥å…·
  - [ ] å®ç°é•œåƒåˆ†å±‚ä¼˜åŒ–
  - [ ] æ”¯æŒå¤šæ¶æ„é•œåƒæ„å»º

- [ ] **å®‰å…¨åŠ å›º**
  - [ ] å®æ–½å®¹å™¨å®‰å…¨æ‰«æ
  - [ ] æ·»åŠ é•œåƒç­¾åéªŒè¯
  - [ ] å®ç°è¿è¡Œæ—¶å®‰å…¨ç­–ç•¥
  - [ ] å®¹å™¨æ¼æ´è‡ªåŠ¨ä¿®å¤

- [ ] **æ€§èƒ½è°ƒä¼˜**
  - [ ] å®¹å™¨å¯åŠ¨æ—¶é—´ä¼˜åŒ–
  - [ ] å†…å­˜ä½¿ç”¨ä¼˜åŒ–
  - [ ] CPUä½¿ç”¨ä¼˜åŒ–
  - [ ] ç½‘ç»œæ€§èƒ½ä¼˜åŒ–

#### 1.2 ç¼–æ’èƒ½åŠ›å¢å¼º

- [ ] **Docker Composeå¢å¼º**
  - [ ] æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–
  - [ ] å®ç°æœåŠ¡ä¾èµ–ç®¡ç†
  - [ ] æ·»åŠ å¥åº·æ£€æŸ¥é…ç½®
  - [ ] æ”¯æŒæœåŠ¡æ‰©å±•é…ç½®

- [ ] **Kubernetesé›†æˆ**
  - [ ] å®Œå–„K8séƒ¨ç½²æ¨¡æ¿
  - [ ] å®ç°Helm Chart
  - [ ] æ·»åŠ K8s Operator
  - [ ] æ”¯æŒK8sæœåŠ¡ç½‘æ ¼

- [ ] **æœåŠ¡å‘ç°ä¼˜åŒ–**
  - [ ] å®ç°æ™ºèƒ½æœåŠ¡å‘ç°
  - [ ] æ”¯æŒå¤šæ³¨å†Œä¸­å¿ƒ
  - [ ] æ·»åŠ æœåŠ¡å¥åº·ç›‘æ§
  - [ ] å®ç°è´Ÿè½½å‡è¡¡ç­–ç•¥

### 2. ä¸­æœŸè§„åˆ’ (6-12ä¸ªæœˆ)

#### 2.1 äº‘åŸç”Ÿè½¬å‹

- [ ] **å¤šäº‘æ”¯æŒ**
  - [ ] AWS EKSé›†æˆ
  - [ ] Google GKEé›†æˆ
  - [ ] Azure AKSé›†æˆ
  - [ ] äº‘æœåŠ¡æŠ½è±¡å±‚

- [ ] **GitOpså®è·µ**
  - [ ] å®ç°GitOpså·¥ä½œæµ
  - [ ] é›†æˆArgoCD
  - [ ] åŸºç¡€è®¾æ–½å³ä»£ç 
  - [ ] è‡ªåŠ¨åŒ–éƒ¨ç½²æµæ°´çº¿

- [ ] **å¯è§‚æµ‹æ€§å¢å¼º**
  - [ ] åˆ†å¸ƒå¼è¿½è¸ªé›†æˆ
  - [ ] æ—¥å¿—èšåˆä¼˜åŒ–
  - [ ] ç›‘æ§é¢æ¿å®šåˆ¶
  - [ ] å‘Šè­¦ç­–ç•¥ä¼˜åŒ–

#### 2.2 æ™ºèƒ½åŒ–è¿ç»´

- [ ] **è‡ªåŠ¨åŒ–è¿ç»´**
  - [ ] æ™ºèƒ½æ‰©ç¼©å®¹ç®—æ³•
  - [ ] è‡ªåŠ¨æ•…éšœæ¢å¤
  - [ ] é¢„æµ‹æ€§ç»´æŠ¤
  - [ ] è‡ªæ„ˆç³»ç»Ÿ

- [ ] **æˆæœ¬ä¼˜åŒ–**
  - [ ] èµ„æºä½¿ç”¨ä¼˜åŒ–
  - [ ] è‡ªåŠ¨æˆæœ¬æ§åˆ¶
  - [ ] é—²ç½®èµ„æºæ¸…ç†
  - [ ] å¤šäº‘æˆæœ¬æ¯”è¾ƒ

### 3. é•¿æœŸè§„åˆ’ (12-24ä¸ªæœˆ)

#### 3.1 å¹³å°åŒ–å‘å±•

- [ ] **éƒ¨ç½²å¹³å°**
  - [ ] Webç•Œé¢éƒ¨ç½²ç®¡ç†
  - [ ] ä¸€é”®éƒ¨ç½²ä½“éªŒ
  - [ ] éƒ¨ç½²æ¨¡æ¿å¸‚åœº
  - [ ] éƒ¨ç½²å†å²ç®¡ç†

- [ ] **ç”Ÿæ€ç³»ç»Ÿå»ºè®¾**
  - [ ] ç¬¬ä¸‰æ–¹é›†æˆæ”¯æŒ
  - [ ] éƒ¨ç½²å·¥å…·æ’ä»¶åŒ–
  - [ ] å¼€æºè´¡çŒ®è€…å·¥å…·
  - [ ] ç¤¾åŒºæœ€ä½³å®è·µ

#### 3.2 ä¸‹ä¸€ä»£åŸºç¡€è®¾æ–½

- [ ] **Serverlessé›†æˆ**
  - [ ] FaaSå¹³å°é›†æˆ
  - [ ] äº‹ä»¶é©±åŠ¨æ¶æ„
  - [ ] è‡ªåŠ¨å¼¹æ€§ä¼¸ç¼©
  - [ ] æˆæœ¬ä¼˜åŒ–ç®—æ³•

- [ ] **è¾¹ç¼˜è®¡ç®—æ”¯æŒ**
  - [ ] è¾¹ç¼˜èŠ‚ç‚¹éƒ¨ç½²
  - [ ] åœ°ç†ä½ç½®è·¯ç”±
  - [ ] ç¦»çº¿å¤„ç†èƒ½åŠ›
  - [ ] è¾¹ç¼˜æ•°æ®åŒæ­¥

---

## ğŸ”— ä¾èµ–å…³ç³»

### 1. å†…éƒ¨ä¾èµ–

#### 1.1 å¼ºä¾èµ–æ¨¡å—

```
éƒ¨ç½²æ¨¡å—ä¾èµ–å…³ç³»:
â”œâ”€â”€ æ ¸å¿ƒæ¨¡å— (Core Module)
â”‚   â”œâ”€â”€ éƒ¨ç½²AIè·¯ç”±é€»è¾‘
â”‚   â””â”€â”€ æä¾›é…ç½®æ¨¡æ¿
â”œâ”€â”€ é…ç½®æ¨¡å— (Config Module)
â”‚   â”œâ”€â”€ è¯»å–éƒ¨ç½²é…ç½®
â”‚   â””â”€â”€ ç®¡ç†ç¯å¢ƒå˜é‡
â”œâ”€â”€ æµ‹è¯•æ¨¡å— (Test Module)
â”‚   â”œâ”€â”€ é›†æˆéƒ¨ç½²æµ‹è¯•
â”‚   â””â”€â”€ æ€§èƒ½æµ‹è¯•ç¯å¢ƒ
â””â”€â”€ ç®¡ç†æ¨¡å— (Admin Module)
    â”œâ”€â”€ æä¾›éƒ¨ç½²ç®¡ç†ç•Œé¢
    â””â”€â”€ ç›‘æ§éƒ¨ç½²çŠ¶æ€
```

#### 1.2 å¯é€‰ä¾èµ–æ¨¡å—

```
å¯é€‰ä¾èµ–:
â”œâ”€â”€ å·¥å…·æ¨¡å— (Bin Module) - æä¾›éƒ¨ç½²å·¥å…·
â””â”€â”€ æ–‡æ¡£æ¨¡å— (Docs Module) - ç”Ÿæˆéƒ¨ç½²æ–‡æ¡£
```

### 2. å¤–éƒ¨ä¾èµ–

#### 2.1 å®¹å™¨åŒ–ä¾èµ–

```json
{
  "Docker": {
    "docker": "^20.10.0",
    "docker-compose": "^2.0.0",
    "buildx": "^0.10.0"
  },
  "å®¹å™¨å·¥å…·": {
    "dockerode": "^3.3.0",
    "docker-compose-viz": "^1.0.0"
  }
}
```

#### 2.2 ç¼–æ’ä¾èµ–

```json
{
  "Kubernetes": {
    "@kubernetes/client-node": "^0.18.0",
    "kubernetes-models": "^4.0.0",
    "kubectl": "^1.0.0"
  },
  "Helm": {
    "@kubernetes/helm": "^1.0.0",
    "js-yaml": "^4.1.0"
  },
  "Istio": {
    "istio-models": "^1.0.0"
  }
}
```

#### 2.3 äº‘æœåŠ¡ä¾èµ–

```json
{
  "AWS": {
    "@aws-sdk/client-ecs": "^3.360.0",
    "@aws-sdk/client-ecr": "^3.360.0",
    "@aws-sdk/client-eks": "^3.360.0"
  },
  "Google Cloud": {
    "@google-cloud/container": "^4.0.0",
    "@google-cloud/artifact-registry": "^2.0.0"
  },
  "Azure": {
    "@azure/arm-containerservice": "^19.0.0",
    "@azure/container-registry": "^1.0.0"
  }
}
```

#### 2.4 ç›‘æ§è¿ç»´ä¾èµ–

```json
{
  "Prometheus": {
    "prom-client": "^14.0.0",
    "prometheus-api-metrics": "^3.2.2"
  },
  "Grafana": {
    "@grafana/runtime": "^10.0.0",
    "@grafana/ui": "^10.0.0"
  },
  "ELK Stack": {
    "winston": "^3.8.0",
    "@elastic/elasticsearch": "^8.0.0"
  }
}
```

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### 1. éƒ¨ç½²æµ‹è¯•

#### 1.1 å®¹å™¨æµ‹è¯•

**é•œåƒæµ‹è¯•ç­–ç•¥**:

```javascript
class ContainerTestSuite {
  // é•œåƒæ„å»ºæµ‹è¯•
  static async testImageBuild(dockerfile, context) {
    console.log('ğŸ—ï¸ Testing Docker image build...');

    const buildResult = await docker.buildImage({
      context,
      dockerfile,
      t: 'test-image:latest',
    });

    // éªŒè¯é•œåƒæ„å»ºæˆåŠŸ
    const image = docker.getImage('test-image:latest');
    const imageInfo = await image.inspect();

    // æ£€æŸ¥é•œåƒå¤§å°
    expect(imageInfo.Size).toBeLessThan(500 * 1024 * 1024); // 500MB

    // æ£€æŸ¥å¥åº·æ£€æŸ¥
    expect(imageInfo.Config.Healthcheck).toBeDefined();

    // æ£€æŸ¥å®‰å…¨é…ç½®
    expect(imageInfo.Config.User).not.toBe('root');

    console.log('âœ… Image build test passed');
  }

  // å®¹å™¨è¿è¡Œæµ‹è¯•
  static async testContainerRun(imageName) {
    console.log('ğŸš€ Testing container runtime...');

    const container = await docker.createContainer({
      Image: imageName,
      Cmd: ['npm', 'test'],
      Env: ['NODE_ENV=test'],
    });

    await container.start();

    // ç­‰å¾…å®¹å™¨å®Œæˆ
    const result = await container.wait();

    // æ£€æŸ¥é€€å‡ºç 
    expect(result.StatusCode).toBe(0);

    // æ£€æŸ¥å®¹å™¨æ—¥å¿—
    const logs = await container.logs({
      stdout: true,
      stderr: true,
    });

    expect(logs).not.toContain('ERROR');
    expect(logs).toContain('All tests passed');

    await container.remove();
    console.log('âœ… Container runtime test passed');
  }

  // é•œåƒå®‰å…¨æµ‹è¯•
  static async testImageSecurity(imageName) {
    console.log('ğŸ”’ Testing image security...');

    // è¿è¡ŒTrivyå®‰å…¨æ‰«æ
    const scanResult = await exec(`trivy image --format json ${imageName}`);

    const vulnerabilities = JSON.parse(scanResult);

    // æ£€æŸ¥é«˜å±æ¼æ´
    const highSeverity = vulnerabilities.filter(v => v.Severity === 'HIGH');
    expect(highSeverity.length).toBe(0);

    // æ£€æŸ¥å…³é”®æ¼æ´
    const criticalSeverity = vulnerabilities.filter(
      v => v.Severity === 'CRITICAL'
    );
    expect(criticalSeverity.length).toBe(0);

    console.log('âœ… Image security test passed');
  }

  // é•œåƒæ€§èƒ½æµ‹è¯•
  static async testImagePerformance(imageName) {
    console.log('âš¡ Testing image performance...');

    const container = await docker.createContainer({
      Image: imageName,
      Cmd: ['node', '-e', 'console.log("warmup")'],
    });

    const startTime = Date.now();
    await container.start();
    await container.wait();
    const startupTime = Date.now() - startTime;

    // æ£€æŸ¥å¯åŠ¨æ—¶é—´
    expect(startupTime).toBeLessThan(5000); // 5ç§’å†…å¯åŠ¨

    await container.remove();
    console.log('âœ… Image performance test passed');
  }
}
```

#### 1.2 ç¼–æ’æµ‹è¯•

**Docker Composeæµ‹è¯•**:

```javascript
class ComposeTestSuite {
  // Composeæ–‡ä»¶éªŒè¯
  static async testComposeFile(composeFile) {
    console.log('ğŸ“‹ Testing Docker Compose configuration...');

    // éªŒè¯YAMLè¯­æ³•
    const composeConfig = yaml.load(fs.readFileSync(composeFile, 'utf8'));

    // æ£€æŸ¥å¿…éœ€çš„æœåŠ¡
    expect(composeConfig.services).toHaveProperty('app');
    expect(composeConfig.services).toHaveProperty('db');

    // éªŒè¯æœåŠ¡é…ç½®
    for (const [serviceName, serviceConfig] of Object.entries(
      composeConfig.services
    )) {
      // æ£€æŸ¥é•œåƒæˆ–æ„å»ºé…ç½®
      expect(serviceConfig.image || serviceConfig.build).toBeDefined();

      // æ£€æŸ¥ç«¯å£æ˜ å°„
      if (serviceConfig.ports) {
        serviceConfig.ports.forEach(port => {
          expect(port).toMatch(/^\d+:\d+$/);
        });
      }

      // æ£€æŸ¥ç¯å¢ƒå˜é‡
      if (serviceConfig.environment) {
        Object.values(serviceConfig.environment).forEach(env => {
          expect(typeof env).toBe('string');
        });
      }

      // æ£€æŸ¥å¥åº·æ£€æŸ¥
      if (serviceConfig.healthcheck) {
        expect(serviceConfig.healthcheck.test).toBeDefined();
        expect(serviceConfig.healthcheck.interval).toBeDefined();
      }
    }

    console.log('âœ… Compose configuration test passed');
  }

  // Composeéƒ¨ç½²æµ‹è¯•
  static async testComposeDeployment(composeFile, projectName) {
    console.log('ğŸš€ Testing Docker Compose deployment...');

    try {
      // å¯åŠ¨æœåŠ¡
      await exec(`docker-compose -f ${composeFile} -p ${projectName} up -d`);

      // ç­‰å¾…æœåŠ¡å°±ç»ª
      await this.waitForServices(projectName, 30000);

      // éªŒè¯æœåŠ¡å¥åº·
      await this.verifyServiceHealth(projectName);

      console.log('âœ… Compose deployment test passed');
    } finally {
      // æ¸…ç†èµ„æº
      await exec(`docker-compose -f ${composeFile} -p ${projectName} down -v`);
    }
  }

  // Kuberneteséƒ¨ç½²æµ‹è¯•
  static async testK8sDeployment(manifests) {
    console.log('â˜¸ï¸ Testing Kubernetes deployment...');

    try {
      // åº”ç”¨æ¸…å•
      for (const manifest of manifests) {
        await exec(`kubectl apply -f ${manifest}`);
      }

      // ç­‰å¾…éƒ¨ç½²å°±ç»ª
      await exec(
        'kubectl wait --for=condition=available --timeout=300s deployment/sira-gateway'
      );

      // éªŒè¯æœåŠ¡
      await this.verifyK8sServices();

      // è¿è¡Œé›†æˆæµ‹è¯•
      await this.runIntegrationTestsInK8s();

      console.log('âœ… Kubernetes deployment test passed');
    } finally {
      // æ¸…ç†èµ„æº
      for (const manifest of manifests.reverse()) {
        await exec(`kubectl delete -f ${manifest} --ignore-not-found=true`);
      }
    }
  }
}
```

---

## ğŸ”§ ç»´æŠ¤è®¡åˆ’

### 1. æ—¥å¸¸ç»´æŠ¤

#### 1.1 å®¹å™¨ç»´æŠ¤

**é•œåƒç®¡ç†**:

- [ ] å®šæœŸæ¸…ç†æœªä½¿ç”¨é•œåƒ
- [ ] æ›´æ–°åŸºç¡€é•œåƒç‰ˆæœ¬
- [ ] ç›‘æ§é•œåƒå¤§å°å˜åŒ–
- [ ] å®‰å…¨è¡¥ä¸åŠæ—¶åº”ç”¨

**å®¹å™¨ç›‘æ§**:

- [ ] å®¹å™¨èµ„æºä½¿ç”¨ç›‘æ§
- [ ] å®¹å™¨å¥åº·çŠ¶æ€æ£€æŸ¥
- [ ] å®¹å™¨æ—¥å¿—æ”¶é›†åˆ†æ
- [ ] å¼‚å¸¸å®¹å™¨è‡ªåŠ¨é‡å¯

#### 1.2 ç¼–æ’ç»´æŠ¤

**Docker Composeç»´æŠ¤**:

- [ ] æœåŠ¡é…ç½®å®šæœŸå®¡æŸ¥
- [ ] ç¯å¢ƒå˜é‡å®‰å…¨æ£€æŸ¥
- [ ] ç½‘ç»œé…ç½®ä¼˜åŒ–
- [ ] å­˜å‚¨å·æ¸…ç†ç­–ç•¥

**Kubernetesç»´æŠ¤**:

- [ ] é›†ç¾¤ç‰ˆæœ¬å‡çº§è§„åˆ’
- [ ] èµ„æºé…é¢ç®¡ç†
- [ ] ç½‘ç»œç­–ç•¥å®¡æŸ¥
- [ ] å®‰å…¨ä¸Šä¸‹æ–‡æ£€æŸ¥

### 2. ç‰ˆæœ¬ç®¡ç†

#### 2.1 é•œåƒç‰ˆæœ¬ç®¡ç†

**è¯­ä¹‰åŒ–ç‰ˆæœ¬ç­–ç•¥**:

```
é•œåƒç‰ˆæœ¬æ ¼å¼: MAJOR.MINOR.PATCH-TAG
- MAJOR: é‡å¤§æ¶æ„å˜æ›´æˆ–ä¸å…¼å®¹æ›´æ–°
- MINOR: æ–°åŠŸèƒ½æ·»åŠ æˆ–å‘åå…¼å®¹æ”¹è¿›
- PATCH: ç¼ºé™·ä¿®å¤æˆ–å°å¹…ä¼˜åŒ–
- TAG: ç¯å¢ƒæ ‡è¯† (latest, staging, production)
```

**ç‰ˆæœ¬ç®¡ç†æµç¨‹**:

```javascript
class ImageVersionManager {
  // ç”Ÿæˆç‰ˆæœ¬å·
  generateVersion(changes, currentVersion) {
    const [major, minor, patch] = currentVersion.split('.').map(Number);

    // åˆ†æå˜æ›´ç±»å‹
    const hasBreakingChanges = changes.some(c => c.type === 'breaking');
    const hasNewFeatures = changes.some(c => c.type === 'feature');
    const hasBugFixes = changes.some(c => c.type === 'fix');

    if (hasBreakingChanges) {
      return `${major + 1}.0.0`;
    } else if (hasNewFeatures) {
      return `${major}.${minor + 1}.0`;
    } else if (hasBugFixes) {
      return `${major}.${minor}.${patch + 1}`;
    } else {
      return currentVersion; // æ— éœ€ç‰ˆæœ¬æ›´æ–°
    }
  }

  // å‘å¸ƒé•œåƒ
  async releaseImage(imageName, version, tags = []) {
    const fullImageName = `${imageName}:${version}`;

    // æ¨é€ä¸»ç‰ˆæœ¬
    await docker.push(fullImageName);

    // æ¨é€æ ‡ç­¾ç‰ˆæœ¬
    for (const tag of tags) {
      const taggedImage = `${imageName}:${tag}`;
      await docker.tag(fullImageName, taggedImage);
      await docker.push(taggedImage);
    }

    // æ›´æ–°æœ€æ–°æ ‡ç­¾
    if (tags.includes('latest')) {
      await docker.tag(fullImageName, `${imageName}:latest`);
      await docker.push(`${imageName}:latest`);
    }

    // è®°å½•å‘å¸ƒä¿¡æ¯
    await this.recordRelease(version, tags);
  }

  // æ¸…ç†æ—§ç‰ˆæœ¬
  async cleanupOldVersions(imageName, keepVersions = 10) {
    const allTags = await this.listImageTags(imageName);
    const sortedVersions = this.sortVersions(allTags);

    const versionsToDelete = sortedVersions.slice(keepVersions);

    for (const version of versionsToDelete) {
      try {
        await docker.removeImage(`${imageName}:${version}`);
        console.log(`ğŸ—‘ï¸ Removed old image: ${imageName}:${version}`);
      } catch (error) {
        console.warn(`Failed to remove ${version}:`, error.message);
      }
    }
  }
}
```

#### 2.2 éƒ¨ç½²é…ç½®ç®¡ç†

**é…ç½®ç‰ˆæœ¬æ§åˆ¶**:

```javascript
class DeploymentConfigManager {
  // é…ç½®ç‰ˆæœ¬åŒ–
  async versionDeploymentConfig(config, environment) {
    const version = this.generateConfigVersion(config);
    const snapshot = {
      version,
      environment,
      config: deepClone(config),
      timestamp: new Date(),
      checksum: this.calculateConfigChecksum(config),
      author: this.getCurrentUser(),
    };

    await this.store.saveDeploymentVersion(snapshot);
    return version;
  }

  // é…ç½®å˜æ›´æ£€æµ‹
  async detectConfigChanges(environment) {
    const currentConfig = await this.getCurrentDeploymentConfig(environment);
    const baselineConfig = await this.getBaselineConfig(environment);

    return this.compareConfigs(baselineConfig, currentConfig);
  }

  // é…ç½®å›æ»š
  async rollbackDeploymentConfig(environment, version) {
    const snapshot = await this.store.getDeploymentVersion(
      environment,
      version
    );

    // éªŒè¯é…ç½®
    await this.validateDeploymentConfig(snapshot.config);

    // åº”ç”¨é…ç½®
    await this.applyDeploymentConfig(environment, snapshot.config);

    // è®°å½•å›æ»š
    await this.recordRollback(environment, version);
  }
}
```

### 3. æŠ€æœ¯å€ºåŠ¡ç®¡ç†

#### 3.1 éƒ¨ç½²å€ºåŠ¡è¯†åˆ«

**å®¹å™¨åŒ–å€ºåŠ¡**:

- [ ] é•œåƒå¤§å°è¶…æ ‡
- [ ] å®‰å…¨æ¼æ´æœªä¿®å¤
- [ ] ä¾èµ–åŒ…ç‰ˆæœ¬è¿‡æ—§
- [ ] æ„å»ºæ—¶é—´è¿‡é•¿

**ç¼–æ’å€ºåŠ¡**:

- [ ] é…ç½®å¤æ‚åº¦è¿‡é«˜
- [ ] ç¯å¢ƒå·®å¼‚æœªéš”ç¦»
- [ ] æ‰©å±•æ€§è®¾è®¡ä¸è¶³
- [ ] ç›‘æ§è¦†ç›–ä¸å…¨

#### 3.2 å€ºåŠ¡å¿è¿˜è®¡åˆ’

**ä¼˜å…ˆçº§æ’åº**:

1. **P0 (ç´§æ€¥)**: å½±å“éƒ¨ç½²ç¨³å®šæ€§çš„å€ºåŠ¡
2. **P1 (é‡è¦)**: å½±å“éƒ¨ç½²æ•ˆç‡çš„å€ºåŠ¡
3. **P2 (ä¸€èˆ¬)**: å½±å“ä»£ç å¯ç»´æŠ¤æ€§çš„å€ºåŠ¡

**å¿è¿˜ç­–ç•¥**:

- [ ] æ¯ä¸ªæœˆåº¦å‘å¸ƒå‰å¿è¿˜è‡³å°‘3ä¸ªéƒ¨ç½²å€ºåŠ¡é¡¹
- [ ] è®¾ç«‹éƒ¨ç½²å€ºåŠ¡KPIæŒ‡æ ‡ (æ¯æœˆå‡å°‘15%)
- [ ] å®šæœŸéƒ¨ç½²å€ºåŠ¡è¯„å®¡ä¼šè®®

### 4. æ–‡æ¡£ç»´æŠ¤

#### 4.1 éƒ¨ç½²æ–‡æ¡£ä½“ç³»

**æ–‡æ¡£ç»“æ„**:

- [ ] **å¿«é€Ÿå¼€å§‹**: 5åˆ†é’Ÿæœ¬åœ°éƒ¨ç½²æŒ‡å—
- [ ] **éƒ¨ç½²æ‰‹å†Œ**: è¯¦ç»†éƒ¨ç½²é…ç½®è¯´æ˜
- [ ] **è¿ç»´æŒ‡å—**: æ—¥å¸¸è¿ç»´å’Œæ•…éšœæ’é™¤
- [ ] **æœ€ä½³å®è·µ**: éƒ¨ç½²ä¼˜åŒ–å’Œæ€§èƒ½è°ƒä¼˜

**è‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆ**:

```javascript
class DeploymentDocumentationGenerator {
  // ç”Ÿæˆéƒ¨ç½²æŒ‡å—
  async generateDeploymentGuide() {
    const environments = await this.getSupportedEnvironments();
    const guide = {
      introduction: 'Sira AI Gateway Deployment Guide',
      prerequisites: await this.generatePrerequisites(),
      environments: {},
      troubleshooting: await this.generateTroubleshooting(),
    };

    for (const env of environments) {
      guide.environments[env.name] = await this.generateEnvironmentGuide(env);
    }

    return guide;
  }

  // ç”Ÿæˆç¯å¢ƒç‰¹å®šæŒ‡å—
  async generateEnvironmentGuide(environment) {
    return {
      name: environment.name,
      description: environment.description,
      requirements: environment.requirements,
      steps: await this.generateDeploymentSteps(environment),
      configuration: await this.generateConfigurationGuide(environment),
      verification: await this.generateVerificationSteps(environment),
    };
  }

  // ç”Ÿæˆæ•…éšœæ’é™¤æŒ‡å—
  async generateTroubleshooting() {
    const commonIssues = await this.getCommonDeploymentIssues();

    return commonIssues.map(issue => ({
      problem: issue.problem,
      symptoms: issue.symptoms,
      causes: issue.causes,
      solutions: issue.solutions,
      prevention: issue.prevention,
    }));
  }
}
```

---

## ğŸ“Š æˆåŠŸæŒ‡æ ‡

### 1. éƒ¨ç½²è´¨é‡æŒ‡æ ‡

#### 1.1 å®¹å™¨åŒ–æŒ‡æ ‡

- [ ] **é•œåƒå¤§å°**: < 200MB (è¿è¡Œæ—¶é•œåƒ)
- [ ] **æ„å»ºæ—¶é—´**: < 5åˆ†é’Ÿ (CIç¯å¢ƒ)
- [ ] **å¯åŠ¨æ—¶é—´**: < 30ç§’ (å†·å¯åŠ¨)
- [ ] **å®‰å…¨æ¼æ´**: 0ä¸ªé«˜å±æ¼æ´

#### 1.2 ç¼–æ’æŒ‡æ ‡

- [ ] **éƒ¨ç½²æˆåŠŸç‡**: > 99% (è‡ªåŠ¨åŒ–éƒ¨ç½²)
- [ ] **æœåŠ¡å¯ç”¨æ€§**: > 99.9% (ç”Ÿäº§ç¯å¢ƒ)
- [ ] **æ‰©ç¼©å®¹æ—¶é—´**: < 2åˆ†é’Ÿ (è‡ªåŠ¨æ‰©ç¼©å®¹)
- [ ] **é…ç½®ä¸€è‡´æ€§**: 100% (å¤šç¯å¢ƒé…ç½®)

### 2. è¿ç»´æ•ˆç‡æŒ‡æ ‡

#### 2.1 ç›‘æ§è¦†ç›–æŒ‡æ ‡

- [ ] **å®¹å™¨ç›‘æ§**: 100% å®¹å™¨èµ„æºç›‘æ§
- [ ] **åº”ç”¨ç›‘æ§**: 100% åº”ç”¨æ€§èƒ½ç›‘æ§
- [ ] **å‘Šè­¦å“åº”**: < 5åˆ†é’Ÿ å¹³å‡å“åº”æ—¶é—´
- [ ] **é—®é¢˜å®šä½**: < 15åˆ†é’Ÿ å¹³å‡å®šä½æ—¶é—´

#### 2.2 è‡ªåŠ¨åŒ–ç¨‹åº¦æŒ‡æ ‡

- [ ] **éƒ¨ç½²è‡ªåŠ¨åŒ–**: 100% ç”Ÿäº§éƒ¨ç½²è‡ªåŠ¨åŒ–
- [ ] **å›æ»šè‡ªåŠ¨åŒ–**: 100% æ•…éšœå›æ»šè‡ªåŠ¨åŒ–
- [ ] **ç›‘æ§è‡ªåŠ¨åŒ–**: 95% å¼‚å¸¸æ£€æµ‹è‡ªåŠ¨åŒ–
- [ ] **ç»´æŠ¤è‡ªåŠ¨åŒ–**: 90% æ—¥å¸¸ç»´æŠ¤è‡ªåŠ¨åŒ–

### 3. æˆæœ¬æ•ˆç›ŠæŒ‡æ ‡

#### 3.1 èµ„æºåˆ©ç”¨æŒ‡æ ‡

- [ ] **CPUåˆ©ç”¨ç‡**: 60-80% (ç”Ÿäº§ç¯å¢ƒå¹³å‡)
- [ ] **å†…å­˜åˆ©ç”¨ç‡**: 70-85% (ç”Ÿäº§ç¯å¢ƒå¹³å‡)
- [ ] **å­˜å‚¨åˆ©ç”¨ç‡**: < 80% (é•¿æœŸå­˜å‚¨)
- [ ] **ç½‘ç»œåˆ©ç”¨ç‡**: < 70% (å³°å€¼å¸¦å®½)

#### 3.2 æˆæœ¬æ§åˆ¶æŒ‡æ ‡

- [ ] **éƒ¨ç½²æˆæœ¬**: < $0.1/å°æ—¶ (åŸºç¡€é…ç½®)
- [ ] **è¿ç»´æˆæœ¬**: < $0.05/å°æ—¶ (è‡ªåŠ¨åŒ–è¿ç»´)
- [ ] **æ•…éšœæ¢å¤æˆæœ¬**: < $100/æ¬¡ (è‡ªåŠ¨åŒ–æ¢å¤)
- [ ] **æ‰©å±•æˆæœ¬**: çº¿æ€§æ‰©å±• (èµ„æºä½¿ç”¨çº¿æ€§å¢é•¿)

---

## ğŸ¯ æ€»ç»“

éƒ¨ç½²æ¨¡å—ä½œä¸ºSira AIç½‘å…³çš„"åŸºç¡€è®¾æ–½å¼•æ“"ï¼Œæ‰¿æ‹…ç€å®¹å™¨åŒ–ã€ç¼–æ’éƒ¨ç½²ã€ç›‘æ§è¿ç»´ç­‰å…³é”®èŒè´£ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„Dockeré•œåƒç­–ç•¥ã€Kubernetesç¼–æ’æ–¹æ¡ˆã€ç›‘æ§è¿ç»´ä½“ç³»ï¼Œéƒ¨ç½²æ¨¡å—èƒ½å¤Ÿï¼š

**æŠ€æœ¯ä¼˜åŠ¿**:

- å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–é•œåƒå¤§å°å’Œå®‰å…¨
- çµæ´»çš„ç¼–æ’æ–¹æ¡ˆæ”¯æŒå¤šç§éƒ¨ç½²ç¯å¢ƒ
- æ™ºèƒ½çš„å¼¹æ€§ä¼¸ç¼©å’Œè‡ªåŠ¨è¿ç»´
- å…¨é¢çš„å¯è§‚æµ‹æ€§å’Œæ•…éšœè‡ªæ„ˆ

**ä¸šåŠ¡ä»·å€¼**:

- ç®€åŒ–éƒ¨ç½²æµç¨‹ï¼Œæå‡äº¤ä»˜æ•ˆç‡
- ä¿éšœç³»ç»Ÿç¨³å®šæ€§ï¼Œç¡®ä¿é«˜å¯ç”¨æ€§
- ä¼˜åŒ–èµ„æºä½¿ç”¨ï¼Œæ§åˆ¶è¿è¥æˆæœ¬
- æä¾›å®Œæ•´è¿ç»´èƒ½åŠ›ï¼Œæ”¯æŒå¿«é€Ÿæ•…éšœæ¢å¤

**æ¶æ„äº®ç‚¹**:

- åŸºç¡€è®¾æ–½å³ä»£ç å®ç°è‡ªåŠ¨åŒ–éƒ¨ç½²
- é…ç½®æ¼‚ç§»æ£€æµ‹ä¿éšœç¯å¢ƒä¸€è‡´æ€§
- æ¸è¿›å¼éƒ¨ç½²ç­–ç•¥ç¡®ä¿å¹³æ»‘å‡çº§
- å¤šå±‚æ¬¡ç›‘æ§å®ç°å…¨æ–¹ä½å¯è§‚æµ‹

é€šè¿‡æŒç»­çš„æŠ€æœ¯åˆ›æ–°å’Œæœ€ä½³å®è·µåº”ç”¨ï¼Œéƒ¨ç½²æ¨¡å—å°†æˆä¸ºç°ä»£åŒ–åº”ç”¨éƒ¨ç½²çš„æ ‡å‡†è§£å†³æ–¹æ¡ˆï¼Œä¸ºå›¢é˜Ÿæä¾›ç¨³å®šã€é«˜æ•ˆã€è‡ªåŠ¨åŒ–çš„åŸºç¡€è®¾æ–½ç®¡ç†èƒ½åŠ›ã€‚
