/**
 * Sira AIç½‘å…³ - è´Ÿè½½æµ‹è¯•å·¥å…·
 * åŸºäºApache JMeterã€Locustã€k6çš„æœ€ä½³å®è·µï¼Œå®ç°é«˜æ€§èƒ½è´Ÿè½½æµ‹è¯•
 */

const EventEmitter = require('events')
const axios = require('axios')
const { performance } = require('perf_hooks')

/**
 * è´Ÿè½½æµ‹è¯•å·¥å…·
 * æ”¯æŒå¤šç§è´Ÿè½½æ¨¡å¼ï¼šæ’å®šè´Ÿè½½ã€é˜¶æ¢¯è´Ÿè½½ã€å³°å€¼è´Ÿè½½ã€éšæœºè´Ÿè½½
 */
class LoadTestingTool extends EventEmitter {
  constructor(options = {}) {
    super()

    this.options = {
      baseUrl: options.baseUrl || 'http://localhost:8080',
      maxConcurrency: options.maxConcurrency || 100,
      rampUpTime: options.rampUpTime || 60, // ç§’
      testDuration: options.testDuration || 300, // ç§’
      cooldownTime: options.cooldownTime || 30, // ç§’
      requestTimeout: options.requestTimeout || 30000, // æ¯«ç§’
      enableMetrics: options.enableMetrics !== false,
      ...options
    }

    // æµ‹è¯•çŠ¶æ€
    this.isRunning = false
    this.startTime = null
    this.endTime = null

    // è´Ÿè½½é…ç½®
    this.loadProfiles = {
      constant: this.constantLoad.bind(this),
      ramp: this.rampLoad.bind(this),
      spike: this.spikeLoad.bind(this),
      random: this.randomLoad.bind(this),
      stress: this.stressLoad.bind(this)
    }

    // ç»Ÿè®¡æ•°æ®
    this.stats = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      totalResponseTime: 0,
      minResponseTime: Infinity,
      maxResponseTime: 0,
      responseTimes: [],
      errors: new Map(),
      throughput: [],
      concurrency: [],
      timestamps: []
    }

    // HTTPå®¢æˆ·ç«¯é…ç½®
    this.httpClient = axios.create({
      baseURL: this.options.baseUrl,
      timeout: this.options.requestTimeout,
      headers: {
        'Content-Type': 'application/json',
        'User-Agent': 'Sira-Load-Tester/1.0'
      }
    })

    // æµ‹è¯•åœºæ™¯
    this.testScenarios = new Map()
  }

  /**
   * åˆå§‹åŒ–è´Ÿè½½æµ‹è¯•å·¥å…·
   */
  async initialize() {
    console.log('ğŸ”§ åˆå§‹åŒ–è´Ÿè½½æµ‹è¯•å·¥å…·')
    this.setupDefaultScenarios()
  }

  /**
   * è®¾ç½®é»˜è®¤æµ‹è¯•åœºæ™¯
   */
  setupDefaultScenarios() {
    // AIèŠå¤©åœºæ™¯
    this.addScenario('ai_chat', {
      name: 'AIèŠå¤©è´Ÿè½½æµ‹è¯•',
      endpoint: '/chat/completions',
      method: 'POST',
      payload: {
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'user', content: 'è¯·å†™ä¸€æ®µå…³äºäººå·¥æ™ºèƒ½çš„çŸ­æ–‡' }
        ],
        max_tokens: 100,
        temperature: 0.7
      },
      headers: {
        'Authorization': 'Bearer sk-test-key',
        'Content-Type': 'application/json'
      }
    })

    // å‚æ•°ç®¡ç†åœºæ™¯
    this.addScenario('parameter_management', {
      name: 'å‚æ•°ç®¡ç†è´Ÿè½½æµ‹è¯•',
      endpoint: '/parameters/optimize',
      method: 'POST',
      payload: {
        parameters: {
          temperature: 0.8,
          top_p: 0.9,
          frequency_penalty: 0.1,
          presence_penalty: 0.1
        },
        task_type: 'creative'
      }
    })

    // æ‰¹é‡å¤„ç†åœºæ™¯
    this.addScenario('batch_processing', {
      name: 'æ‰¹é‡å¤„ç†è´Ÿè½½æµ‹è¯•',
      endpoint: '/batch-processing/batches',
      method: 'POST',
      payload: {
        requests: Array.from({ length: 10 }, (_, i) => ({
          id: `req_${i}`,
          model: 'gpt-3.5-turbo',
          prompt: `è¯·ç”Ÿæˆç¬¬${i + 1}ä¸ªæµ‹è¯•æ–‡æœ¬`
        }))
      }
    })

    // æµå¼å“åº”åœºæ™¯
    this.addScenario('streaming', {
      name: 'æµå¼å“åº”è´Ÿè½½æµ‹è¯•',
      endpoint: '/streaming/streams',
      method: 'POST',
      payload: {
        userId: 'test_user',
        options: {
          maxConnections: 5
        }
      }
    })
  }

  /**
   * æ·»åŠ æµ‹è¯•åœºæ™¯
   */
  addScenario(name, config) {
    this.testScenarios.set(name, {
      name: config.name || name,
      endpoint: config.endpoint,
      method: config.method || 'GET',
      payload: config.payload || {},
      headers: config.headers || {},
      setup: config.setup,
      teardown: config.teardown
    })
  }

  /**
   * è¿è¡Œè´Ÿè½½æµ‹è¯•
   */
  async runLoadTest(config) {
    const {
      scenario = 'ai_chat',
      loadProfile = 'ramp',
      targetRPS = 10,
      duration = this.options.testDuration,
      maxConcurrency = this.options.maxConcurrency
    } = config

    if (this.isRunning) {
      throw new Error('è´Ÿè½½æµ‹è¯•å·²åœ¨è¿è¡Œä¸­')
    }

    this.isRunning = true
    this.startTime = Date.now()
    this.resetStats()

    console.log(`ğŸš€ å¼€å§‹è´Ÿè½½æµ‹è¯•: ${scenario} (${loadProfile}æ¨¡å¼)`)

    this.emit('testStart', {
      scenario,
      loadProfile,
      targetRPS,
      duration,
      maxConcurrency
    })

    try {
      const scenarioConfig = this.testScenarios.get(scenario)
      if (!scenarioConfig) {
        throw new Error(`æµ‹è¯•åœºæ™¯ä¸å­˜åœ¨: ${scenario}`)
      }

      const loadFunction = this.loadProfiles[loadProfile]
      if (!loadFunction) {
        throw new Error(`è´Ÿè½½æ¨¡å¼ä¸å­˜åœ¨: ${loadProfile}`)
      }

      // æ‰§è¡Œè´Ÿè½½æµ‹è¯•
      await loadFunction({
        scenario: scenarioConfig,
        targetRPS,
        duration,
        maxConcurrency
      })

      this.endTime = Date.now()

      const results = this.generateReport()

      this.emit('testComplete', results)

      return results

    } catch (error) {
      console.error('è´Ÿè½½æµ‹è¯•å¤±è´¥:', error.message)
      this.emit('testError', error)
      throw error
    } finally {
      this.isRunning = false
    }
  }

  /**
   * æ’å®šè´Ÿè½½æ¨¡å¼
   */
  async constantLoad(config) {
    const { scenario, targetRPS, duration, maxConcurrency } = config
    const interval = 1000 / targetRPS // è¯·æ±‚é—´éš”(æ¯«ç§’)
    const endTime = Date.now() + (duration * 1000)

    console.log(`ğŸ“Š æ’å®šè´Ÿè½½æ¨¡å¼: ${targetRPS} RPS, æŒç»­ ${duration} ç§’`)

    const workers = []
    for (let i = 0; i < Math.min(maxConcurrency, targetRPS); i++) {
      workers.push(this.createWorker(scenario, interval, endTime))
    }

    await Promise.all(workers)
  }

  /**
   * é˜¶æ¢¯è´Ÿè½½æ¨¡å¼
   */
  async rampLoad(config) {
    const { scenario, targetRPS, duration, maxConcurrency } = config
    const rampUpTime = this.options.rampUpTime * 1000
    const endTime = Date.now() + (duration * 1000)

    console.log(`ğŸ“ˆ é˜¶æ¢¯è´Ÿè½½æ¨¡å¼: 0 -> ${targetRPS} RPS, æŒç»­ ${duration} ç§’`)

    let currentRPS = 0
    const rpsIncrement = targetRPS / (rampUpTime / 1000)

    while (Date.now() < endTime && currentRPS < targetRPS) {
      currentRPS = Math.min(currentRPS + rpsIncrement, targetRPS)
      const interval = 1000 / currentRPS

      const workers = []
      for (let i = 0; i < Math.min(maxConcurrency, Math.ceil(currentRPS)); i++) {
        workers.push(this.createWorker(scenario, interval, Math.min(endTime, Date.now() + 1000)))
      }

      await Promise.all(workers)
    }
  }

  /**
   * å³°å€¼è´Ÿè½½æ¨¡å¼
   */
  async spikeLoad(config) {
    const { scenario, targetRPS, duration, maxConcurrency } = config
    const spikeDuration = 10 // 10ç§’å³°å€¼
    const normalRPS = targetRPS * 0.2
    const endTime = Date.now() + (duration * 1000)

    console.log(`âš¡ å³°å€¼è´Ÿè½½æ¨¡å¼: å³°å€¼ ${targetRPS} RPS, æŒç»­ ${duration} ç§’`)

    while (Date.now() < endTime) {
      const isSpike = Math.random() < 0.3 // 30%æ—¶é—´å¤„äºå³°å€¼
      const currentRPS = isSpike ? targetRPS : normalRPS
      const interval = 1000 / currentRPS

      const spikeEndTime = Math.min(endTime, Date.now() + (isSpike ? spikeDuration * 1000 : 5000))

      const workers = []
      for (let i = 0; i < Math.min(maxConcurrency, Math.ceil(currentRPS)); i++) {
        workers.push(this.createWorker(scenario, interval, spikeEndTime))
      }

      await Promise.all(workers)
    }
  }

  /**
   * éšæœºè´Ÿè½½æ¨¡å¼
   */
  async randomLoad(config) {
    const { scenario, targetRPS, duration, maxConcurrency } = config
    const endTime = Date.now() + (duration * 1000)

    console.log(`ğŸ² éšæœºè´Ÿè½½æ¨¡å¼: å¹³å‡ ${targetRPS} RPS, æŒç»­ ${duration} ç§’`)

    while (Date.now() < endTime) {
      // æ­£æ€åˆ†å¸ƒéšæœºRPS
      const variation = (Math.random() - 0.5) * 0.5 // Â±50%å˜åŒ–
      const currentRPS = Math.max(1, targetRPS * (1 + variation))
      const interval = 1000 / currentRPS

      const workers = []
      for (let i = 0; i < Math.min(maxConcurrency, Math.ceil(currentRPS)); i++) {
        workers.push(this.createWorker(scenario, interval, Math.min(endTime, Date.now() + 1000)))
      }

      await Promise.all(workers)
    }
  }

  /**
   * å‹åŠ›æµ‹è¯•æ¨¡å¼
   */
  async stressLoad(config) {
    const { scenario, targetRPS, duration, maxConcurrency } = config
    const endTime = Date.now() + (duration * 1000)
    let currentConcurrency = 1

    console.log(`ğŸ’¥ å‹åŠ›æµ‹è¯•æ¨¡å¼: é€’å¢å¹¶å‘æ•°ç›´åˆ° ${maxConcurrency}, æŒç»­ ${duration} ç§’`)

    while (Date.now() < endTime && currentConcurrency <= maxConcurrency) {
      const interval = 1000 / targetRPS

      const workers = []
      for (let i = 0; i < currentConcurrency; i++) {
        workers.push(this.createWorker(scenario, interval, Math.min(endTime, Date.now() + 5000)))
      }

      await Promise.all(workers)

      // æ¯5ç§’å¢åŠ å¹¶å‘æ•°
      currentConcurrency = Math.min(currentConcurrency * 2, maxConcurrency)
    }
  }

  /**
   * åˆ›å»ºå·¥ä½œçº¿ç¨‹
   */
  createWorker(scenario, interval, endTime) {
    return new Promise(async (resolve) => {
      const timer = setInterval(async () => {
        if (Date.now() >= endTime) {
          clearInterval(timer)
          resolve()
          return
        }

        try {
          await this.makeRequest(scenario)
        } catch (error) {
          // é™é»˜å¤„ç†è¯·æ±‚é”™è¯¯ï¼Œç»§ç»­æµ‹è¯•
        }
      }, interval)
    })
  }

  /**
   * å‘é€HTTPè¯·æ±‚
   */
  async makeRequest(scenario) {
    const startTime = performance.now()

    try {
      const response = await this.httpClient.request({
        url: scenario.endpoint,
        method: scenario.method,
        data: scenario.payload,
        headers: scenario.headers
      })

      const responseTime = performance.now() - startTime

      this.recordSuccess(responseTime, response.status)

    } catch (error) {
      const responseTime = performance.now() - startTime
      this.recordFailure(responseTime, error)
    }
  }

  /**
   * è®°å½•æˆåŠŸè¯·æ±‚
   */
  recordSuccess(responseTime, statusCode) {
    this.stats.totalRequests++
    this.stats.successfulRequests++
    this.stats.totalResponseTime += responseTime

    if (responseTime < this.stats.minResponseTime) {
      this.stats.minResponseTime = responseTime
    }
    if (responseTime > this.stats.maxResponseTime) {
      this.stats.maxResponseTime = responseTime
    }

    this.stats.responseTimes.push(responseTime)

    // è®°å½•ååé‡ï¼ˆæ¯ç§’è¯·æ±‚æ•°ï¼‰
    const timestamp = Date.now()
    this.stats.throughput.push({
      timestamp,
      rps: 1,
      responseTime
    })

    this.emit('requestSuccess', {
      responseTime,
      statusCode,
      timestamp
    })
  }

  /**
   * è®°å½•å¤±è´¥è¯·æ±‚
   */
  recordFailure(responseTime, error) {
    this.stats.totalRequests++
    this.stats.failedRequests++
    this.stats.totalResponseTime += responseTime

    const errorType = error.code || error.response?.status || 'UNKNOWN'
    this.stats.errors.set(errorType, (this.stats.errors.get(errorType) || 0) + 1)

    this.emit('requestFailure', {
      responseTime,
      error: error.message,
      type: errorType
    })
  }

  /**
   * é‡ç½®ç»Ÿè®¡æ•°æ®
   */
  resetStats() {
    this.stats = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      totalResponseTime: 0,
      minResponseTime: Infinity,
      maxResponseTime: 0,
      responseTimes: [],
      errors: new Map(),
      throughput: [],
      concurrency: [],
      timestamps: []
    }
  }

  /**
   * ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
   */
  generateReport() {
    const duration = (this.endTime - this.startTime) / 1000 // ç§’
    const avgResponseTime = this.stats.totalRequests > 0 ?
      this.stats.totalResponseTime / this.stats.totalRequests : 0
    const successRate = this.stats.totalRequests > 0 ?
      (this.stats.successfulRequests / this.stats.totalRequests * 100).toFixed(2) : 0
    const avgRPS = this.stats.totalRequests / duration

    // è®¡ç®—å“åº”æ—¶é—´åˆ†å¸ƒ
    const responseTimePercentiles = this.calculatePercentiles(this.stats.responseTimes, [50, 95, 99])

    // è®¡ç®—ååé‡è¶‹åŠ¿
    const throughputTrend = this.calculateThroughputTrend()

    return {
      summary: {
        duration,
        totalRequests: this.stats.totalRequests,
        successfulRequests: this.stats.successfulRequests,
        failedRequests: this.stats.failedRequests,
        successRate: `${successRate}%`,
        averageRPS: avgRPS.toFixed(2),
        averageResponseTime: `${avgResponseTime.toFixed(2)}ms`,
        minResponseTime: this.stats.totalRequests > 0 ? `${this.stats.minResponseTime.toFixed(2)}ms` : 'N/A',
        maxResponseTime: this.stats.totalRequests > 0 ? `${this.stats.maxResponseTime.toFixed(2)}ms` : 'N/A'
      },
      responseTimeDistribution: {
        p50: responseTimePercentiles[50] !== undefined ? `${responseTimePercentiles[50].toFixed(2)}ms` : 'N/A',
        p95: responseTimePercentiles[95] !== undefined ? `${responseTimePercentiles[95].toFixed(2)}ms` : 'N/A',
        p99: responseTimePercentiles[99] !== undefined ? `${responseTimePercentiles[99].toFixed(2)}ms` : 'N/A'
      },
      errors: Object.fromEntries(this.stats.errors),
      throughput: throughputTrend,
      recommendations: this.generateRecommendations(successRate, avgResponseTime, avgRPS)
    }
  }

  /**
   * è®¡ç®—ç™¾åˆ†ä½æ•°
   */
  calculatePercentiles(values, percentiles) {
    if (values.length === 0) return {}

    const sorted = [...values].sort((a, b) => a - b)
    const result = {}

    percentiles.forEach(p => {
      const index = Math.ceil((p / 100) * sorted.length) - 1
      result[p] = sorted[Math.max(0, Math.min(index, sorted.length - 1))]
    })

    return result
  }

  /**
   * è®¡ç®—ååé‡è¶‹åŠ¿
   */
  calculateThroughputTrend() {
    if (this.stats.throughput.length === 0) return []

    // æŒ‰æ—¶é—´çª—å£èšåˆååé‡
    const windowSize = 5000 // 5ç§’çª—å£
    const windows = new Map()

    this.stats.throughput.forEach(point => {
      const window = Math.floor(point.timestamp / windowSize) * windowSize
      if (!windows.has(window)) {
        windows.set(window, { count: 0, totalTime: 0 })
      }
      const data = windows.get(window)
      data.count++
      data.totalTime += point.responseTime
    })

    return Array.from(windows.entries())
      .sort(([a], [b]) => a - b)
      .map(([timestamp, data]) => ({
        timestamp,
        rps: data.count / (windowSize / 1000),
        avgResponseTime: data.totalTime / data.count
      }))
  }

  /**
   * ç”Ÿæˆæµ‹è¯•å»ºè®®
   */
  generateRecommendations(successRate, avgResponseTime, avgRPS) {
    const recommendations = []

    if (parseFloat(successRate) < 95) {
      recommendations.push('æˆåŠŸç‡ä½äº95%ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿç¨³å®šæ€§æˆ–å¢åŠ èµ„æº')
    }

    if (avgResponseTime > 1000) {
      recommendations.push('å¹³å‡å“åº”æ—¶é—´è¶…è¿‡1ç§’ï¼Œå»ºè®®ä¼˜åŒ–æ€§èƒ½æˆ–å¢åŠ ç¼“å­˜')
    }

    if (avgRPS < 10) {
      recommendations.push('å¹³å‡RPSè¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿé…ç½®æˆ–ç½‘ç»œå»¶è¿Ÿ')
    }

    if (this.stats.errors.size > 0) {
      const topError = Array.from(this.stats.errors.entries())
        .sort(([,a], [,b]) => b - a)[0]
      recommendations.push(`æœ€å¸¸è§çš„é”™è¯¯: ${topError[0]} (${topError[1]}æ¬¡)`)
    }

    return recommendations
  }

  /**
   * åœæ­¢è´Ÿè½½æµ‹è¯•
   */
  stop() {
    this.isRunning = false
    console.log('ğŸ›‘ è´Ÿè½½æµ‹è¯•å·²åœæ­¢')
    this.emit('testStopped')
  }

  /**
   * è·å–å½“å‰çŠ¶æ€
   */
  getStatus() {
    return {
      isRunning: this.isRunning,
      startTime: this.startTime,
      duration: this.startTime ? Date.now() - this.startTime : 0,
      stats: {
        totalRequests: this.stats.totalRequests,
        successfulRequests: this.stats.successfulRequests,
        failedRequests: this.stats.failedRequests,
        currentRPS: this.stats.totalRequests / Math.max(1, (Date.now() - (this.startTime || Date.now())) / 1000)
      }
    }
  }
}

module.exports = { LoadTestingTool }
