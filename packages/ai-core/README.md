# @sira/ai-core - AIæ ¸å¿ƒæœåŠ¡

AIæ ¸å¿ƒæœåŠ¡æä¾›å¤šAIæœåŠ¡å•†é›†æˆã€æ™ºèƒ½è¯·æ±‚å¤„ç†å’Œå“åº”æ ¼å¼åŒ–åŠŸèƒ½ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ¤– **å¤šAIæœåŠ¡å•†æ”¯æŒ**: OpenAIã€Anthropicã€Googleç­‰
- ğŸ”„ **æ™ºèƒ½é‡è¯•**: è‡ªåŠ¨é‡è¯•å¤±è´¥è¯·æ±‚
- ğŸ“Š **æŒ‡æ ‡ç›‘æ§**: è¯¦ç»†çš„æ€§èƒ½å’Œä½¿ç”¨ç»Ÿè®¡
- ğŸ¯ **æ¨¡å‹ç®¡ç†**: ç»Ÿä¸€æ¨¡å‹é…ç½®å’Œåˆ‡æ¢
- âš¡ **æµå¼å“åº”**: æ”¯æŒå®æ—¶æµå¼è¾“å‡º

## å®‰è£…ä½¿ç”¨

```javascript
const { AIServiceManager, AIRequest, AIResponse } = require('@sira/ai-core');

const aiManager = new AIServiceManager({
  timeout: 30000,
  maxRetries: 3
});

// æ³¨å†ŒAIæä¾›å•†
aiManager.registerProvider('openai', openaiProvider);
aiManager.registerModel('gpt-4', 'openai', { maxTokens: 4000 });

// æ‰§è¡Œè¯·æ±‚
const response = await aiManager.executeRequest({
  model: 'gpt-4',
  messages: [{ role: 'user', content: 'Hello!' }]
});
```

## API æ¥å£

### AIServiceManager

#### æ„é€ å‡½æ•°
```javascript
new AIServiceManager(options)
```

**å‚æ•°:**
- `options` (Object): é…ç½®é€‰é¡¹
  - `timeout` (number): è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤30000ms
  - `maxRetries` (number): æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤3
  - `retryDelay` (number): é‡è¯•å»¶è¿Ÿï¼Œé»˜è®¤1000ms
  - `metrics` (Object): æŒ‡æ ‡æ”¶é›†å™¨
  - `logger` (Object): æ—¥å¿—è®°å½•å™¨

#### æ–¹æ³•

##### `registerProvider(name, provider)`
æ³¨å†ŒAIæä¾›å•†ã€‚

```javascript
aiManager.registerProvider('openai', openaiProvider)
```

**å‚æ•°:**
- `name` (string): æä¾›å•†åç§°
- `provider` (Object): æä¾›å•†å®ä¾‹

##### `registerModel(modelName, providerName, modelConfig)`
æ³¨å†ŒAIæ¨¡å‹ã€‚

```javascript
aiManager.registerModel('gpt-4', 'openai', {
  maxTokens: 4000,
  pricing: { prompt: 0.03, completion: 0.06 }
})
```

**å‚æ•°:**
- `modelName` (string): æ¨¡å‹åç§°
- `providerName` (string): æä¾›å•†åç§°
- `modelConfig` (Object): æ¨¡å‹é…ç½®

##### `executeRequest(request, options)`
æ‰§è¡ŒAIè¯·æ±‚ã€‚

```javascript
const response = await aiManager.executeRequest({
  model: 'gpt-4',
  messages: [{ role: 'user', content: 'Hello!' }],
  temperature: 0.7
})
```

**å‚æ•°:**
- `request` (Object): è¯·æ±‚é…ç½®
  - `model` (string): æ¨¡å‹åç§°
  - `messages` (Array): æ¶ˆæ¯æ•°ç»„
  - å…¶ä»–æ¨¡å‹å‚æ•°
- `options` (Object): æ‰§è¡Œé€‰é¡¹

**è¿”å›:** Promise<AIResponse>

##### `executeStreamingRequest(request, options)`
æ‰§è¡Œæµå¼AIè¯·æ±‚ã€‚

```javascript
for await (const chunk of aiManager.executeStreamingRequest(request)) {
  console.log(chunk.content);
}
```

**å‚æ•°:**
- `request` (Object): è¯·æ±‚é…ç½®
- `options` (Object): æ‰§è¡Œé€‰é¡¹

**è¿”å›:** AsyncIterable<StreamChunk>

##### `getModel(modelName)`
è·å–æ¨¡å‹é…ç½®ã€‚

```javascript
const model = aiManager.getModel('gpt-4')
```

**å‚æ•°:**
- `modelName` (string): æ¨¡å‹åç§°

**è¿”å›:** æ¨¡å‹é…ç½®å¯¹è±¡æˆ–null

##### `getAvailableModels()`
è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹ã€‚

```javascript
const models = aiManager.getAvailableModels()
```

**è¿”å›:** æ¨¡å‹ä¿¡æ¯æ•°ç»„

##### `validateModel(modelName)`
éªŒè¯æ¨¡å‹å¯ç”¨æ€§ã€‚

```javascript
const result = await aiManager.validateModel('gpt-4')
```

**è¿”å›:**
```javascript
{
  valid: true,        // æ˜¯å¦æœ‰æ•ˆ
  error: null         // é”™è¯¯ä¿¡æ¯
}
```

##### `getStats()`
è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯ã€‚

```javascript
const stats = aiManager.getStats()
```

**è¿”å›:**
```javascript
{
  providers: ['openai', 'anthropic'],
  models: ['gpt-4', 'claude-3'],
  capabilities: ['chat', 'completion', 'embedding']
}
```

### AIRequest

#### æ„é€ å‡½æ•°
```javascript
new AIRequest(model, messages, options)
```

**å‚æ•°:**
- `model` (string): æ¨¡å‹åç§°
- `messages` (Array): æ¶ˆæ¯æ•°ç»„
- `options` (Object): è¯·æ±‚é€‰é¡¹

#### æ–¹æ³•

##### `addMessage(message)`
æ·»åŠ æ¶ˆæ¯ã€‚

```javascript
request.addMessage({ role: 'user', content: 'How are you?' })
```

##### `setOption(key, value)`
è®¾ç½®è¯·æ±‚é€‰é¡¹ã€‚

```javascript
request.setOption('temperature', 0.8)
```

##### `toAPIFormat()`
è½¬æ¢ä¸ºAPIæ ¼å¼ã€‚

```javascript
const apiFormat = request.toAPIFormat()
```

### AIResponse

#### æ„é€ å‡½æ•°
```javascript
new AIResponse(content, usage, metadata)
```

**å‚æ•°:**
- `content` (string): å“åº”å†…å®¹
- `usage` (Object): ä½¿ç”¨ç»Ÿè®¡
- `metadata` (Object): å…ƒæ•°æ®

#### æ–¹æ³•

##### `getContent()`
è·å–å“åº”å†…å®¹ã€‚

```javascript
const content = response.getContent()
```

##### `getUsage()`
è·å–ä½¿ç”¨ç»Ÿè®¡ã€‚

```javascript
const usage = response.getUsage()
// { promptTokens: 10, completionTokens: 20, totalTokens: 30 }
```

##### `calculateCost(pricing)`
è®¡ç®—è¯·æ±‚æˆæœ¬ã€‚

```javascript
const cost = response.calculateCost({
  prompt: 0.03,      // æç¤ºè¯ä»·æ ¼($/1K tokens)
  completion: 0.06    // å®Œæˆä»·æ ¼($/1K tokens)
})
```

## äº‹ä»¶

AIServiceManagerç»§æ‰¿è‡ªEventEmitterï¼Œä¼šå‘å‡ºä»¥ä¸‹äº‹ä»¶ï¼š

- `providerRegistered`: æä¾›å•†æ³¨å†Œ
- `providerUnregistered`: æä¾›å•†æ³¨é”€
- `modelRegistered`: æ¨¡å‹æ³¨å†Œ
- `requestStart`: è¯·æ±‚å¼€å§‹
- `requestComplete`: è¯·æ±‚å®Œæˆ
- `requestError`: è¯·æ±‚é”™è¯¯
- `streamingRequestStart`: æµå¼è¯·æ±‚å¼€å§‹
- `streamingChunk`: æµå¼æ•°æ®å—
- `streamingRequestComplete`: æµå¼è¯·æ±‚å®Œæˆ
- `streamingRequestError`: æµå¼è¯·æ±‚é”™è¯¯

## ä¾èµ–å…³ç³»

- `@sira/core`: æ ¸å¿ƒæœåŠ¡å®¹å™¨
- `@sira/utils`: å·¥å…·å‡½æ•°

## ç¤ºä¾‹

```javascript
const { AIServiceManager, AIRequest } = require('@sira/ai-core');

async function chatWithAI() {
  const aiManager = new AIServiceManager();

  // æ³¨å†ŒOpenAIæä¾›å•†
  aiManager.registerProvider('openai', openaiProvider);
  aiManager.registerModel('gpt-4', 'openai', {
    maxTokens: 4000,
    temperature: 0.7
  });

  // åˆ›å»ºè¯·æ±‚
  const request = new AIRequest('gpt-4', [
    { role: 'system', content: 'You are a helpful assistant.' },
    { role: 'user', content: 'Explain quantum computing.' }
  ]);

  // æ‰§è¡Œè¯·æ±‚
  try {
    const response = await aiManager.executeRequest(request);
    console.log('Response:', response.getContent());
    console.log('Usage:', response.getUsage());
    console.log('Cost:', response.calculateCost(modelPricing));
  } catch (error) {
    console.error('Error:', error.message);
  }
}
```
