config:
  target: 'http://localhost:3000'
  phases:
    # Warm-up phase
    - duration: 60
      arrivalRate: 1
      name: "Warm-up"
    # Ramp-up phase
    - duration: 120
      arrivalRate: 1
      rampTo: 10
      name: "Ramp-up"
    # Sustained load phase
    - duration: 300
      arrivalRate: 10
      name: "Sustained load"
    # Peak load phase
    - duration: 60
      arrivalRate: 20
      name: "Peak load"
    # Cool-down phase
  defaults:
    headers:
      x-api-key: "test-api-key"
      Content-Type: 'application/json'
  processor: "./tests/processor.js"

scenarios:
  - name: "Chat completions without batching"
    weight: 70
    flow:
      - post:
          url: "/api/v2/chat/completions"
          headers:
            x-enable-batch: "false"
          json:
            model: "gpt-3.5-turbo"
            messages:
              - role: "user"
                content: "Write a short haiku about {{ haiku_topic }}"
            temperature: 0.7
            max_tokens: 100

  - name: "Chat completions with batching"
    weight: 20
    flow:
      - post:
          url: "/api/v2/chat/completions"
          headers:
            x-enable-batch: "true"
          json:
            model: "gpt-3.5-turbo"
            messages:
              - role: "user"
                content: "Summarize the following text in one sentence: {{ summary_text }}"
            temperature: 0.7
            max_tokens: 50

  - name: "Embeddings with batching"
    weight: 10
    flow:
      - post:
          url: "/api/v2/embeddings"
          headers:
            x-enable-batch: "true"
          json:
            model: "text-embedding-ada-002"
            input: "{{ embedding_texts }}"

  - name: "Health check"
    weight: 5
    flow:
      - get:
          url: "/health"

  - name: "Metrics endpoint"
    weight: 5
    flow:
      - get:
          url: "/metrics"
